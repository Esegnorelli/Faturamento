"""
Dashboard Inteligente Modularizado (v2.2)
==================================================

Esta vers√£o traz um conjunto de otimiza√ß√µes, refatora√ß√µes e melhorias de legibilidade
para a aplica√ß√£o de dashboard baseada em Streamlit. O objetivo principal foi
simplificar a estrutura de c√≥digo, adicionar tipagem expl√≠cita, organizar
fun√ß√µes auxiliares e documentar melhor o fluxo de execu√ß√£o. Al√©m disso,
mantemos total compatibilidade com a vers√£o anterior (2.1) e preservamos todas as
funcionalidades existentes, incluindo as an√°lises comparativa, preditiva,
detalhada e mobile.

Principais mudan√ßas nesta revis√£o:

* **Tipagem aprimorada**: foram adicionadas anota√ß√µes de tipo a praticamente
  todas as fun√ß√µes, melhorando a autocompletude em IDEs e a robustez durante
  o desenvolvimento.
* **Docstrings detalhadas**: cada fun√ß√£o agora possui uma descri√ß√£o clara de
  seu prop√≥sito, par√¢metros e valor de retorno, facilitando a compreens√£o do
  c√≥digo por novos desenvolvedores.
* **Organiza√ß√£o e coment√°rios**: o c√≥digo foi reorganizado em se√ß√µes mais
  coesas com coment√°rios explicativos, proporcionando melhor leitura e
  manuten√ß√£o.
* **Pequenas otimiza√ß√µes**: algumas opera√ß√µes de agrupamento e c√°lculos
  intermedi√°rios foram ajustados para reduzir repeti√ß√µes e melhorar a
  performance em cen√°rios com conjuntos de dados maiores.
* **Compatibilidade estendida**: mantivemos as verifica√ß√µes defensivas para
  bibliotecas opcionais como `statsmodels`, garantindo que o dashboard funcione
  mesmo em ambientes onde essas depend√™ncias n√£o estejam dispon√≠veis.

Para executar o aplicativo utilize o comando:
```bash
streamlit run app.py
```

Depend√™ncias recomendadas: streamlit, pandas, plotly, python-dateutil,
statsmodels (opcional), numpy e scipy.
"""

from __future__ import annotations

import os
import re
import unicodedata
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import warnings

warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from scipy.stats import pearsonr

# Tipagem
from typing import Optional, Any, Dict, Tuple, List, Sequence, Callable

# Blindamos o import de statsmodels para evitar falhas em deploys sem a depend√™ncia
try:
    import statsmodels.api as sm  # type: ignore
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
except ModuleNotFoundError:
    sm = None  # type: ignore
    ExponentialSmoothing = None  # type: ignore


# =============================================================================
# CONFIGURA√á√ïES E TEMA
# =============================================================================

def configure_page() -> None:
    """Configura a p√°gina Streamlit e define temas e estilos gerais.

    Esta fun√ß√£o inicializa a configura√ß√£o da p√°gina, definindo t√≠tulo,
    √≠cone, layout e itens de menu. Tamb√©m declara paletas de cores globais
    utilizadas em gr√°ficos e componentes visuais, e injeta CSS customizado
    para ajustar o estilo de elementos espec√≠ficos como cabe√ßalho e cart√µes.
    """
    st.set_page_config(
        page_title="Dashboard Avan√ßado ‚Äî Hora do Pastel",
        page_icon="ü•ü",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            "Get Help": "https://www.streamlit.io/community",
            "Report a bug": "mailto:admin@horadopastel.com",
            "About": "### Dashboard Inteligente v2.2\nDesenvolvido para an√°lise avan√ßada de vendas.",
        },
    )

    # Paleta de cores global
    global theme_colors, custom_colors
    theme_colors = {
        "primary": "#FF6B35",
        "secondary": "#004E89",
        "success": "#28A745",
        "warning": "#FFC107",
        "danger": "#DC3545",
        "info": "#17A2B8",
    }
    custom_colors = [
        "#FF6B35",
        "#004E89",
        "#28A745",
        "#FFC107",
        "#DC3545",
        "#17A2B8",
        "#6C757D",
        "#343A40",
    ]

    # Aplica template e cores padr√£o do Plotly
    px.defaults.template = "plotly_white"
    px.defaults.color_discrete_sequence = custom_colors

    # CSS adicional para componentes
    st.markdown(
        """
        <style>
            .main-header {
                background: linear-gradient(90deg, #FF6B35, #004E89);
                padding: 1rem; border-radius: 10px; color: white;
                text-align: center; margin-bottom: 2rem;
            }
            .metric-card {
                background: white; padding: 1rem; border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1); text-align: center;
                color: #212529;
            }
            .alert-success { background:#d4edda; border:1px solid #c3e6cb; color:#155724; padding:1rem; border-radius:8px; margin:1rem 0; }
            .alert-warning { background:#fff3cd; border:1px solid #ffeaa7; color:#856404; padding:1rem; border-radius:8px; margin:1rem 0; }
            .alert-danger  { background:#f8d7da; border:1px solid #f5c6cb; color:#721c24; padding:1rem; border-radius:8px; margin:1rem 0; }

            /* P√≥dio */
            .podium-container { display:flex; justify-content:center; align-items:flex-end; gap:0.5rem; margin-top:1rem; }
            .podium-item { flex:1; padding:1rem; border-radius:8px; box-shadow:0 2px 4px rgba(0,0,0,0.1); text-align:center; background:white; color:#212529; }
            .podium-item.first { transform: translateY(-15px); }
        </style>
        """,
        unsafe_allow_html=True,
    )


# =============================================================================
# FUN√á√ïES AUXILIARES
# =============================================================================

def normalize_col(name: str) -> str:
    """Normaliza nomes de colunas removendo acentos, espa√ßos e
    convertendo tudo para min√∫sculas.

    Args:
        name: Nome original da coluna.

    Returns:
        Nome normalizado, com acentos retirados e espa√ßos substitu√≠dos por '_'.
    """
    name = name.strip().lower()
    name = "".join(
        c for c in unicodedata.normalize("NFKD", name) if not unicodedata.combining(c)
    )
    return re.sub(r"\s+", "_", name)


def _norm_text(s: str) -> str:
    """Normaliza uma string para compara√ß√£o, removendo acentos e caracteres
    especiais, e convertendo para min√∫sculas.

    Args:
        s: Texto de entrada.

    Returns:
        Vers√£o normalizada contendo apenas caracteres alfanum√©ricos e espa√ßos.
    """
    s = "".join(
        c for c in unicodedata.normalize("NFKD", str(s).strip().lower()) if not unicodedata.combining(c)
    )
    s = re.sub(r"[^a-z0-9 ]", " ", s)
    return " ".join(s.split())


def br_to_float(series: pd.Series) -> pd.Series:
    """Converte strings de valores monet√°rios brasileiros para floats.

    Remove s√≠mbolos, trata separadores de milhar e decimal e converte
    em tipo num√©rico. Valores inv√°lidos s√£o convertidos para NaN.

    Args:
        series: S√©rie contendo strings como 'R$ 1.234,56'.

    Returns:
        S√©rie num√©rica (float64) convertida.
    """
    s = series.astype(str).str.strip()
    s = s.replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    s = s.str.replace(r"[^0-9,\.\-]", "", regex=True)
    has_comma = s.str.contains(",", na=False)
    s = s.mask(has_comma, s.str.replace(".", "", regex=False))
    s = s.mask(has_comma, s.str.replace(",", ".", regex=False))
    return pd.to_numeric(s, errors="coerce")


def month_to_int(series: pd.Series) -> pd.Series:
    """Mapeia nomes de meses em portugu√™s para seu valor inteiro correspondente.

    Args:
        series: S√©rie contendo nomes de meses, abrevia√ß√µes ou n√∫meros.

    Returns:
        S√©rie de inteiros representando meses (1 a 12). Valores
        desconhecidos s√£o convertidos para NaN.
    """
    mapa = {
        "jan": 1, "janeiro": 1,
        "fev": 2, "fevereiro": 2,
        "mar": 3, "marco": 3, "mar√ßo": 3,
        "abr": 4, "abril": 4,
        "mai": 5, "maio": 5,
        "jun": 6, "junho": 6,
        "jul": 7, "julho": 7,
        "ago": 8, "agosto": 8,
        "set": 9, "setembro": 9, "sep": 9,
        "out": 10, "outubro": 10,
        "nov": 11, "novembro": 11,
        "dez": 12, "dezembro": 12,
    }
    s = series.astype(str).str.strip().str.lower().map(lambda x: mapa.get(x, x))
    return pd.to_numeric(s, errors="coerce").astype("Int64")


# Aliases para renomear colunas com termos equivalentes
ALIASES: Dict[str, List[str]] = {
    "mes": ["mes", "m√™s", "month"],
    "ano": ["ano", "year"],
    "loja": ["loja", "filial", "store"],
    "faturamento": ["faturamento", "receita", "vendas", "valor", "total", "valor_total"],
    "pedidos": ["pedidos", "qtde_pedidos", "qtd_pedidos", "qtd", "quantidade_pedidos"],
    "ticket": ["ticket", "ticket_medio", "ticket_m√©dio", "ticket medio", "ticket m√©dio"],
}


def rename_by_alias(cols: Sequence[str]) -> Dict[str, str]:
    """Gera um dicion√°rio de renome baseado em aliases pr√©-definidos.

    Args:
        cols: Lista de nomes de colunas a serem avaliados.

    Returns:
        Mapeamento `{nome_original: nome_normalizado}` de acordo com `ALIASES`.
    """
    ren: Dict[str, str] = {}
    for c in cols:
        for target, opts in ALIASES.items():
            if c in opts:
                ren[c] = target
                break
    return ren


def safe_div(a: Optional[float | int], b: Optional[float | int]) -> float:
    """Realiza uma divis√£o segura entre dois valores num√©ricos.

    Retorna 0.0 caso o divisor seja nulo ou zero, evitando erros. Valores
    inv√°lidos no numerador tamb√©m resultam em 0.0.

    Args:
        a: Numerador.
        b: Denominador.

    Returns:
        Resultado da divis√£o ou 0.0 em casos inv√°lidos.
    """
    try:
        if b in (0, None) or pd.isna(b):
            return 0.0
        return float(a) / float(b) if a not in (None, pd.NA) else 0.0
    except Exception:
        return 0.0


def fmt_brl(v: Any) -> str:
    """Formata um valor num√©rico como moeda brasileira (R$).

    Args:
        v: Valor num√©rico ou None/NaN.

    Returns:
        String formatada no padr√£o 'R$ 1.234,56'. Valores nulos retornam 'R$ 0,00'.
    """
    if pd.isna(v):
        return "R$ 0,00"
    s = f"{float(v):,.2f}"
    return "R$ " + s.replace(",", "X").replace(".", ",").replace("X", ".")


def fmt_int(v: Any) -> str:
    """Formata um valor como inteiro com separador de milhares.

    Args:
        v: Valor num√©rico.

    Returns:
        String representando o inteiro com separadores de milhar. Em caso
        de erro, retorna '0'.
    """
    try:
        return f"{int(v):,}".replace(",", ".")
    except Exception:
        return "0"


def fmt_pct(v: Optional[float], decimals: int = 1) -> str:
    """Formata um valor num√©rico como percentual.

    Args:
        v: Valor entre 0 e 1 (ou None).
        decimals: N√∫mero de casas decimais a exibir.

    Returns:
        String percentual no formato '0,0%'.
    """
    if v is None or pd.isna(v):
        return "0,0%"
    return f"{v * 100:,.{decimals}f}%".replace(".", ",")


def calculate_growth_rate(df_series: pd.Series) -> float:
    """Calcula a taxa de crescimento mensal m√©dio de uma s√©rie temporal.

    A taxa √© calculada como a raiz n-√©sima da raz√£o entre o √∫ltimo e o
    primeiro valor, onde n √© o n√∫mero de intervalos (len - 1). Se o
    valor inicial for menor ou igual a zero, retorna 0.0.

    Args:
        df_series: S√©rie temporal ordenada cronologicamente.

    Returns:
        Taxa de crescimento m√©dio mensal (float).
    """
    if len(df_series) < 2:
        return 0.0
    first_val = df_series.iloc[0]
    last_val = df_series.iloc[-1]
    months = len(df_series) - 1
    if first_val <= 0:
        return 0.0
    try:
        return (last_val / first_val) ** (1 / months) - 1
    except Exception:
        return 0.0


def calculate_volatility(df_series: pd.Series) -> float:
    """Calcula a volatilidade como o desvio padr√£o das varia√ß√µes percentuais.

    Args:
        df_series: S√©rie temporal de valores (e.g., faturamento).

    Returns:
        Desvio padr√£o das varia√ß√µes percentuais mensais. Retorna 0.0 se
        a s√©rie contiver menos de dois pontos ou varia√ß√µes inv√°lidas.
    """
    if len(df_series) < 2:
        return 0.0
    pct_changes = df_series.pct_change().dropna()
    return float(pct_changes.std()) if not pct_changes.empty else 0.0


def detect_seasonality(series: pd.Series) -> str:
    """Classifica a sazonalidade de uma s√©rie temporal agregada por m√™s.

    Utiliza o coeficiente de varia√ß√£o da m√©dia mensal para determinar se
    existe forte sazonalidade (>20%), sazonalidade moderada (>10%) ou baixa
    sazonalidade. Caso a s√©rie possua menos de 12 pontos, retorna
    'Dados insuficientes'. Qualquer falha resulta em 'Indeterminado'.

    Args:
        series: S√©rie temporal indexada por datas.

    Returns:
        String descrevendo o n√≠vel de sazonalidade.
    """
    if len(series) < 12:
        return "Dados insuficientes"
    try:
        s = series.copy()
        s.index = pd.to_datetime(s.index)
        monthly_avg = s.groupby(s.index.month).mean()
        cv = monthly_avg.std() / monthly_avg.mean() if monthly_avg.mean() != 0 else 0.0
        if cv > 0.20:
            return "Alta sazonalidade"
        elif cv > 0.10:
            return "Sazonalidade moderada"
        return "Baixa sazonalidade"
    except Exception:
        return "Indeterminado"


# =============================================================================
# CARGA E TRATAMENTO DE DADOS
# =============================================================================

@st.cache_data(ttl=3600, max_entries=8, show_spinner=False)
def load_data() -> pd.DataFrame:
    """Carrega e pr√©-processa dados de faturamento.

    A fun√ß√£o procura primeiramente por um arquivo j√° tratado
    (`Faturamento_tratado.csv`). Caso n√£o exista, tenta carregar um arquivo
    bruto (`Faturamento.csv`) e realizar o tratamento necess√°rio (normaliza√ß√£o
    de colunas, convers√£o de tipos e cria√ß√£o de colunas derivadas). Quando
    nenhum arquivo √© encontrado, gera um conjunto de dados sint√©tico.

    Returns:
        Um DataFrame com colunas essenciais normalizadas e uma coluna 'data'
        de tipo datetime para uso nas an√°lises temporais.
    """
    def _finalize(df: pd.DataFrame) -> pd.DataFrame:
        """Realiza convers√µes finais e cria coluna de data/periodo.

        Este helper garante que colunas relevantes estejam em tipos
        adequados (Int64 para m√™s, ano e pedidos; float para
        faturamento e ticket) e constr√≥i uma coluna 'data' combinando
        ano, m√™s e dia 1. Tamb√©m cria 'periodo' no formato 'YYYY-MM'.

        Args:
            df: DataFrame parcialmente processado.

        Returns:
            DataFrame pronto para uso nas an√°lises.
        """
        # Convers√µes finais
        for c in ["mes", "ano", "pedidos"]:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce").astype("Int64")
        for c in ["faturamento", "ticket"]:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        if "loja" in df.columns:
            df["loja"] = df["loja"].astype(str).str.strip()
        # Cria coluna de data
        mask = df.get("ano").notna() & df.get("mes").notna()
        df["data"] = pd.NaT
        df.loc[mask, "data"] = pd.to_datetime(
            {"year": df.loc[mask, "ano"].astype(int), "month": df.loc[mask, "mes"].astype(int), "day": 1},
            errors="coerce",
        )
        # Cria coluna per√≠odo AAAA-MM se n√£o existir
        if "periodo" not in df.columns:
            df["periodo"] = pd.to_datetime(df["data"]).dt.to_period("M").astype(str)
        return df.dropna(subset=["data"]).copy()

    # Preferimos arquivo tratado, mas garantimos colunas essenciais
    if os.path.exists("Faturamento_tratado.csv"):
        df = pd.read_csv("Faturamento_tratado.csv")
        base_cols = {"mes", "ano", "loja", "faturamento", "pedidos", "ticket"}
        if not base_cols.issubset(set(map(normalize_col, df.columns))):
            # Normaliza e renomeia apenas se necess√°rio
            df.columns = [normalize_col(c) for c in df.columns]
            df = df.rename(columns=rename_by_alias(list(df.columns)))
            for col in base_cols:
                if col not in df.columns:
                    df[col] = pd.NA
        return _finalize(df)

    # Arquivo bruto
    if os.path.exists("Faturamento.csv"):
        df = pd.read_csv("Faturamento.csv", sep=None, engine="python")
        # Normaliza colunas e remove duplicadas
        df.columns = [normalize_col(c) for c in df.columns]
        df = df.loc[:, ~df.columns.duplicated()].dropna(axis=1, how="all")
        df = df.rename(columns=rename_by_alias(list(df.columns)))
        # Garante colunas essenciais
        for col in ["mes", "ano", "loja", "faturamento", "pedidos", "ticket"]:
            if col not in df.columns:
                df[col] = pd.NA
        # Convers√µes espec√≠ficas
        df["mes"] = month_to_int(df["mes"])
        df["ano"] = pd.to_numeric(df["ano"], errors="coerce").astype("Int64")
        df["faturamento"] = br_to_float(df["faturamento"])
        df["ticket"] = br_to_float(df["ticket"])
        df["pedidos"] = pd.to_numeric(df["pedidos"], errors="coerce").round().astype("Int64")
        return _finalize(df)

    # Caso nenhum arquivo exista, utiliza dados sint√©ticos
    st.warning("Arquivo 'Faturamento.csv' n√£o encontrado. Usando dados de exemplo.")
    return generate_sample_data()


@st.cache_data(ttl=3600, show_spinner=False)
def generate_sample_data() -> pd.DataFrame:
    """Gera um conjunto de dados sint√©ticos para demonstra√ß√£o.

    Os dados simulam faturamento mensal de cinco lojas ao longo de 30 meses,
    incluindo efeitos de sazonalidade, tend√™ncia e um ticket m√©dio derivado
    automaticamente a partir de valores simulados.

    Returns:
        DataFrame contendo colunas ['mes', 'ano', 'loja', 'faturamento',
        'pedidos', 'ticket', 'data', 'periodo'].
    """
    np.random.seed(42)
    lojas = ["Centro", "Shopping A", "Shopping B", "Bairro Norte", "Bairro Sul"]
    start_date = datetime(2022, 1, 1)
    dates = pd.date_range(start_date, periods=30, freq="M")
    data: List[Dict[str, Any]] = []
    for date in dates:
        for loja in lojas:
            base_faturamento = 50000 + np.random.normal(0, 5000)
            seasonal_factor = 1 + 0.2 * np.sin(2 * np.pi * date.month / 12)
            trend_factor = 1 + 0.02 * ((date.year - 2022) * 12 + date.month - 1)
            faturamento = base_faturamento * seasonal_factor * trend_factor
            pedidos = int(max(1, faturamento / max(1, (25 + np.random.normal(0, 5)))))
            ticket = faturamento / pedidos if pedidos > 0 else 0.0
            data.append(
                {
                    "mes": date.month,
                    "ano": date.year,
                    "loja": loja,
                    "faturamento": faturamento,
                    "pedidos": pedidos,
                    "ticket": ticket,
                    "data": date,
                    "periodo": date.strftime("%Y-%m"),
                }
            )
    return pd.DataFrame(data)


# =============================================================================
# FILTROS E SIDEBAR
# =============================================================================

def prepare_filters(df: pd.DataFrame) -> Tuple[str, str, str, List[str], bool, bool, bool]:
    """Exibe controles de filtros na barra lateral e retorna sele√ß√µes do usu√°rio.

    Esta fun√ß√£o cria a interface de filtragem na sidebar do Streamlit,
    permitindo escolher o modo de an√°lise, delimitar o per√≠odo (personalizado
    ou pr√©-definido), selecionar lojas atrav√©s de diferentes crit√©rios e
    habilitar op√ß√µes adicionais como incluir finais de semana ou mostrar
    tend√™ncias/previs√µes.

    Args:
        df: DataFrame principal carregado com os dados de faturamento.

    Returns:
        Uma tupla contendo:
        - analysis_mode: modo de an√°lise selecionado (Padr√£o, Comparativo, etc.).
        - periodo_ini: in√≠cio do intervalo no formato AAAA-MM.
        - periodo_fim: final do intervalo no formato AAAA-MM.
        - sel_lojas: lista de lojas selecionadas.
        - include_weekends: flag para incluir finais de semana (reservado).
        - show_trends: flag para mostrar linhas de tend√™ncia (reservado).
        - show_forecasts: flag para habilitar previs√µes no modo preditivo.
    """
    # Exibe logo se presente no diret√≥rio
    if os.path.exists("logo.png"):
        st.sidebar.image("logo.png", use_container_width=True)

    st.sidebar.markdown("### üéØ Filtros Avan√ßados")

    analysis_mode: str = st.sidebar.selectbox(
        "Modo de An√°lise",
        ["Padr√£o", "Comparativo", "Preditivo", "Detalhado"],
        help="Escolha o tipo de an√°lise desejada",
    )

    # Determina√ß√£o de intervalo de per√≠odo
    periodos = sorted(p for p in df["periodo"].dropna().unique().tolist())
    if len(periodos) < 2:
        st.error("Dados insuficientes para an√°lise. S√£o necess√°rios pelo menos 2 meses de dados.")
        st.stop()

    period_type: str = st.sidebar.selectbox(
        "Tipo de Per√≠odo",
        ["Personalizado", "√öltimos 3M", "√öltimos 6M", "√öltimo Ano", "YTD"],
    )

    # Mapeia a sele√ß√£o do tipo de per√≠odo para um intervalo espec√≠fico
    if period_type == "√öltimos 3M":
        periodo_fim = periodos[-1]
        periodo_ini = periodos[max(0, len(periodos) - 3)]
    elif period_type == "√öltimos 6M":
        periodo_fim = periodos[-1]
        periodo_ini = periodos[max(0, len(periodos) - 6)]
    elif period_type == "√öltimo Ano":
        periodo_fim = periodos[-1]
        periodo_ini = periodos[max(0, len(periodos) - 12)]
    elif period_type == "YTD":
        current_year = datetime.now().year
        ytd_periods = [p for p in periodos if p.startswith(str(current_year))]
        if ytd_periods:
            periodo_ini, periodo_fim = ytd_periods[0], ytd_periods[-1]
        else:
            periodo_ini, periodo_fim = periodos[0], periodos[-1]
    else:
        periodo_ini, periodo_fim = st.sidebar.select_slider(
            "Per√≠odo (AAAA‚ÄëMM)", options=periodos, value=(periodos[0], periodos[-1])
        )

    # Sele√ß√£o de lojas
    st.sidebar.markdown("#### üè™ Sele√ß√£o de Lojas")
    GROUPS: Dict[str, List[str]] = {
        "BGPF": [
            "Caxias do Sul",
            "Bento Goncalves",
            "Novo Hamburgo",
            "Sao leopoldo",
            "Canoas",
            "Prot√°sio Alves",
            "Floresta",
            "Barra Shopping",
        ],
        "Ismael": ["Montenegro", "Lajeado"],
    }

    selection_modes = ["Todas", "Manual", "Por Grupo", "Top Performers", "Personalizadas"]
    selection_mode: str = st.sidebar.radio("Modo de Sele√ß√£o", selection_modes)

    lojas = sorted(df["loja"].dropna().unique().tolist())
    # Mapeia nomes normalizados para a forma original
    map_norm_to_loja = {_norm_text(l): l for l in lojas}

    sel_lojas: List[str]
    if selection_mode == "Todas":
        sel_lojas = lojas
    elif selection_mode == "Manual":
        sel_lojas = st.sidebar.multiselect("Escolha as lojas:", lojas, default=lojas[:3])
    elif selection_mode == "Por Grupo":
        group_name = st.sidebar.selectbox("Escolha o grupo:", list(GROUPS.keys()))
        candidatos = [_norm_text(x) for x in GROUPS.get(group_name, [])]
        sel_lojas = [map_norm_to_loja[c] for c in candidatos if c in map_norm_to_loja]
    elif selection_mode == "Top Performers":
        n_top = st.sidebar.slider("Quantas top lojas?", 3, len(lojas), min(5, len(lojas)))
        top_lojas = (
            df.groupby("loja")["faturamento"].sum().sort_values(ascending=False).head(n_top).index.tolist()
        )
        sel_lojas = top_lojas
    else:
        # Modo personalizado por filtro de desempenho
        min_faturamento = st.sidebar.number_input("Faturamento m√≠nimo (R$)", 0, 1_000_000, 0)
        min_pedidos = st.sidebar.number_input("Pedidos m√≠nimos", 0, 10_000, 0)
        loja_perf = df.groupby("loja").agg({"faturamento": "sum", "pedidos": "sum"}).reset_index()
        filtered = loja_perf[
            (loja_perf["faturamento"] >= min_faturamento) & (loja_perf["pedidos"] >= min_pedidos)
        ]["loja"].tolist()
        sel_lojas = st.sidebar.multiselect("Lojas que atendem crit√©rios:", filtered, default=filtered)

    # Garante que sempre haja pelo menos uma loja selecionada
    if not sel_lojas:
        sel_lojas = lojas[:3]

    # Filtros adicionais (reservados para futuras expans√µes)
    st.sidebar.markdown("#### ‚öôÔ∏è Filtros Adicionais")
    include_weekends = st.sidebar.checkbox("Incluir finais de semana", value=True)
    show_trends = st.sidebar.checkbox("Mostrar linhas de tend√™ncia", value=True)
    show_forecasts = st.sidebar.checkbox("Mostrar previs√µes", value=False)

    return (
        analysis_mode,
        periodo_ini,
        periodo_fim,
        sel_lojas,
        include_weekends,
        show_trends,
        show_forecasts,
    )


# =============================================================================
# PROCESSAMENTO DE DADOS E KPIs
# =============================================================================

def filter_data(
    df: pd.DataFrame, periodo_ini: str, periodo_fim: str, sel_lojas: Sequence[str]
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Aplica filtros de per√≠odo e lojas aos dados originais.

    Args:
        df: DataFrame original com todos os registros.
        periodo_ini: Per√≠odo inicial no formato AAAA-MM.
        periodo_fim: Per√≠odo final no formato AAAA-MM.
        sel_lojas: Lista de lojas selecionadas para an√°lise.

    Returns:
        Um tuple contendo dois DataFrames:
        - df_f: subconjunto filtrado pelo intervalo selecionado e lojas.
        - df_lojas: subconjunto contendo todos os dados das lojas selecionadas (independente do per√≠odo).
    """
    mask = (df["periodo"] >= periodo_ini) & (df["periodo"] <= periodo_fim) & df["loja"].isin(sel_lojas)
    df_f = df.loc[mask].copy()
    df_lojas = df[df["loja"].isin(sel_lojas)].copy()
    return df_f, df_lojas


def delta(cur_v: Optional[float | int], base_v: Optional[float | int]) -> Optional[float]:
    """Calcula a varia√ß√£o percentual entre dois valores.

    Args:
        cur_v: Valor atual.
        base_v: Valor base de compara√ß√£o.

    Returns:
        Percentual de varia√ß√£o ou None se n√£o for poss√≠vel calcular.
    """
    if cur_v is None or base_v in (None, 0) or pd.isna(base_v):
        return None
    return safe_div((float(cur_v) - float(base_v)), float(base_v))


@st.cache_data(show_spinner=False)
def compute_kpis(
    df_range: pd.DataFrame, df_comp: pd.DataFrame, p_ini: str, p_fim: str
) -> Dict[str, Any]:
    """Computa KPIs b√°sicos e avan√ßados para um intervalo e um conjunto de compara√ß√£o.

    A fun√ß√£o agrupa dados temporais, calcula totais, tickets m√©dios, deltas
    (per√≠odo anterior, YoY e MoM) e m√©tricas avan√ßadas como crescimento,
    volatilidade, sazonalidade, correla√ß√£o, ROI estimado e efici√™ncia.

    Args:
        df_range: DataFrame filtrado para o per√≠odo em an√°lise.
        df_comp: DataFrame contendo todos os dados das lojas selecionadas.
        p_ini: In√≠cio do per√≠odo (AAAA-MM).
        p_fim: Fim do per√≠odo (AAAA-MM).

    Returns:
        Um dicion√°rio com m√©tricas calculadas e s√©ries temporais intermedi√°rias.
    """
    # Totais e ticket m√©dio
    tot_fat: float = float(df_range["faturamento"].sum())
    tot_ped: int = int(df_range["pedidos"].sum()) if df_range["pedidos"].notna().any() else 0
    tik_med: float = safe_div(tot_fat, tot_ped)

    # S√©rie temporal agregada por data (todas as lojas selecionadas)
    serie_comp = (
        df_comp.dropna(subset=["data"]).groupby("data", as_index=False).agg(
            faturamento=("faturamento", "sum"), pedidos=("pedidos", "sum")
        ).sort_values("data")
    )

    advanced_metrics: Dict[str, Any] = {}
    if not serie_comp.empty and len(serie_comp) > 1:
        # Crescimento & Volatilidade (requerem pelo menos 3 pontos para robustez)
        advanced_metrics["growth_rate"] = calculate_growth_rate(serie_comp["faturamento"]) if len(serie_comp) > 2 else 0.0
        advanced_metrics["volatility"] = calculate_volatility(serie_comp["faturamento"]) if len(serie_comp) > 2 else 0.0
        # Sazonalidade
        advanced_metrics["seasonality"] = detect_seasonality(
            serie_comp.set_index("data")["faturamento"]
        )
        # Correla√ß√£o pedidos x faturamento (apenas se vari√¢ncia > 0)
        x, y = serie_comp["pedidos"], serie_comp["faturamento"]
        if len(serie_comp) > 3 and np.nanstd(x) > 0 and np.nanstd(y) > 0:
            corr_coef, p_value = pearsonr(x, y)
            advanced_metrics["correlation"] = float(corr_coef)
            advanced_metrics["correlation_pvalue"] = float(p_value)
        # ROI aproximado (20% de margem)
        advanced_metrics["estimated_roi"] = tot_fat * 0.20
        # Efici√™ncia (ticket atual vs hist√≥rico)
        historical_ticket = safe_div(serie_comp["faturamento"].sum(), serie_comp["pedidos"].sum())
        current_efficiency = safe_div(tik_med, historical_ticket) - 1
        advanced_metrics["efficiency"] = current_efficiency

    # Compara√ß√µes temporais (per√≠odo anterior)
    start_date = pd.to_datetime(p_ini)
    end_date = pd.to_datetime(p_fim)
    num_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1

    prev_end_date = start_date - relativedelta(months=1)
    prev_start_date = prev_end_date - relativedelta(months=num_months - 1)
    mask_prev = (df_comp["data"] >= prev_start_date) & (df_comp["data"] <= prev_end_date)
    df_prev_period = df_comp[mask_prev]
    prev_fat: float = float(df_prev_period["faturamento"].sum())
    delta_period_fat: Optional[float] = delta(tot_fat, prev_fat)

    # YoY
    yoy_start_date = start_date - relativedelta(years=1)
    yoy_end_date = end_date - relativedelta(years=1)
    mask_yoy = (df_comp["data"] >= yoy_start_date) & (df_comp["data"] <= yoy_end_date)
    df_yoy_period = df_comp[mask_yoy]
    yoy_fat: float = float(df_yoy_period["faturamento"].sum())
    delta_yoy_fat: Optional[float] = delta(tot_fat, yoy_fat)

    # MoM (m√™s a m√™s comparado ao m√™s anterior imediato)
    mom_fat: Optional[float] = None
    mom_ped: Optional[float] = None
    mom_tik: Optional[float] = None
    if len(serie_comp) >= 2:
        last, prev = serie_comp.iloc[-1], serie_comp.iloc[-2]
        mom_fat = delta(last["faturamento"], prev["faturamento"])
        mom_ped = delta(last["pedidos"], prev["pedidos"])
        last_ticket = safe_div(last["faturamento"], last["pedidos"])
        prev_ticket = safe_div(prev["faturamento"], prev["pedidos"])
        mom_tik = delta(last_ticket, prev_ticket)

    return {
        "period_sum": {"fat": tot_fat, "ped": tot_ped, "tik": tik_med},
        "prev_period_fat": prev_fat,
        "delta_period_fat": delta_period_fat,
        "delta_yoy_fat": delta_yoy_fat,
        "yoy_fat_abs": yoy_fat,
        "mom_fat": mom_fat,
        "mom_ped": mom_ped,
        "mom_tik": mom_tik,
        "advanced": advanced_metrics,
        "serie_temporal": serie_comp,
    }


# =============================================================================
# COMPONENTES DE INTERFACE
# =============================================================================

def display_header(periodo_ini: str, periodo_fim: str, sel_lojas: Sequence[str], analysis_mode: str) -> None:
    """Exibe o cabe√ßalho principal com informa√ß√µes contextuais.

    O cabe√ßalho inclui o t√≠tulo do dashboard e tr√™s indicadores em destaque:
    per√≠odo selecionado, quantidade de lojas analisadas e modo de an√°lise ativo.

    Args:
        periodo_ini: In√≠cio do intervalo selecionado.
        periodo_fim: Fim do intervalo selecionado.
        sel_lojas: Lista de lojas selecionadas.
        analysis_mode: Modo de an√°lise atual.
    """
    st.markdown(
        f"""
        <div class="main-header">
            <h1>ü•ü Dashboard Inteligente ‚Äî Hora do Pastel</h1>
            <p>An√°lise Avan√ßada de Performance e Insights Autom√°ticos</p>
        </div>
        """,
        unsafe_allow_html=True,
    )
    info_col1, info_col2, info_col3 = st.columns(3)
    with info_col1:
        st.info(f"üìÖ **Per√≠odo:** {periodo_ini} a {periodo_fim}")
    with info_col2:
        st.info(f"üè™ **Lojas:** {len(sel_lojas)} selecionadas")
    with info_col3:
        st.info(f"üìä **Modo:** {analysis_mode}")


def display_kpi_panel(k: Dict[str, Any]) -> None:
    """Renderiza o painel principal de KPIs b√°sicos e avan√ßados.

    Os indicadores incluem faturamento total, total de pedidos, ticket m√©dio,
    varia√ß√£o em rela√ß√£o ao per√≠odo anterior, compara√ß√µes YoY, crescimento,
    volatilidade, efici√™ncia e ROI estimado.

    Args:
        k: Dicion√°rio retornado por `compute_kpis` contendo todas as m√©tricas
           necess√°rias.
    """
    st.markdown("### üìä Painel de Indicadores")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(
            label="üí∞ Faturamento Total",
            value=fmt_brl(k["period_sum"]["fat"]),
            delta=fmt_pct(k.get("delta_period_fat", 0) or 0),
            help=f"Per√≠odo anterior: {fmt_brl(k['prev_period_fat'])}",
        )
    with col2:
        st.metric(
            label="üõí Total de Pedidos",
            value=fmt_int(k["period_sum"]["ped"]),
            delta=fmt_pct(k.get("mom_ped", 0) or 0),
            help="Varia√ß√£o MoM do total de pedidos",
        )
    with col3:
        st.metric(
            label="üéØ Ticket M√©dio",
            value=fmt_brl(k["period_sum"]["tik"]),
            delta=fmt_pct(k.get("mom_tik", 0) or 0),
            help="Varia√ß√£o MoM do ticket m√©dio",
        )
    with col4:
        st.metric(
            label="üìà vs Ano Anterior",
            value=fmt_brl(k["period_sum"]["fat"]),
            delta=fmt_pct(k.get("delta_yoy_fat", 0) or 0),
            help=f"Mesmo per√≠odo AA: {fmt_brl(k['yoy_fat_abs'])}",
        )

    # KPIs avan√ßados (growth, volatility, efficiency, ROI)
    if k.get("advanced"):
        col5, col6, col7, col8 = st.columns(4)
        growth_rate = k["advanced"].get("growth_rate", 0)
        volatility = k["advanced"].get("volatility", 0)
        efficiency = k["advanced"].get("efficiency", 0)
        estimated_roi = k["advanced"].get("estimated_roi", 0)
        with col5:
            st.metric("üìä Taxa de Crescimento", fmt_pct(growth_rate), help="Crescimento m√©dio mensal")
        with col6:
            st.metric("üìâ Volatilidade", fmt_pct(volatility), help="Instabilidade das vendas")
        with col7:
            st.metric("‚ö° Efici√™ncia", fmt_pct(efficiency), help="Efici√™ncia vs m√©dia hist√≥rica")
        with col8:
            st.metric("üíé ROI Estimado", fmt_brl(estimated_roi), help="Lucro estimado (margem 20%)")


def display_alerts(k: Dict[str, Any]) -> None:
    """Apresenta alertas e insights r√°pidos baseados nas m√©tricas avan√ßadas.

    A fun√ß√£o utiliza as m√©tricas de crescimento, efici√™ncia, volatilidade e
    sazonalidade para exibir cart√µes visuais que destacam pontos de aten√ß√£o
    ou conquistas. O conte√∫do varia conforme os thresholds definidos.

    Args:
        k: Dicion√°rio retornado por `compute_kpis` contendo as m√©tricas.
    """
    st.markdown("### üö® Alertas e Insights Autom√°ticos")
    alert_col1, alert_col2 = st.columns(2)
    growth_rate = k.get("advanced", {}).get("growth_rate", 0)
    efficiency = k.get("advanced", {}).get("efficiency", 0)
    volatility = k.get("advanced", {}).get("volatility", 0)
    seasonality = k.get("advanced", {}).get("seasonality", "")

    with alert_col1:
        if growth_rate > 0.05:
            st.markdown(
                f"""
                <div class="alert-success">
                    <h4>üöÄ Excelente Crescimento!</h4>
                    <p>Crescimento m√©dio mensal de <strong>{fmt_pct(growth_rate)}</strong> indica performance excepcional.</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        elif growth_rate < -0.02:
            st.markdown(
                f"""
                <div class="alert-danger">
                    <h4>‚ö†Ô∏è Aten√ß√£o: Decl√≠nio nas Vendas</h4>
                    <p>Queda m√©dia mensal de <strong>{fmt_pct(abs(growth_rate))}</strong> requer an√°lise de estrat√©gias.</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                f"""
                <div class="alert-warning">
                    <h4>üìä Crescimento Est√°vel</h4>
                    <p>Crescimento de <strong>{fmt_pct(growth_rate)}</strong> indica estabilidade no per√≠odo.</p>
                </div>
                """,
                unsafe_allow_html=True,
            )

    with alert_col2:
        if efficiency > 0.10:
            st.markdown(
                f"""
                <div class="alert-success">
                    <h4>‚ö° Alta Efici√™ncia</h4>
                    <p>Performance <strong>{fmt_pct(efficiency)}</strong> acima da m√©dia hist√≥rica!</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        elif volatility > 0.30:
            st.markdown(
                f"""
                <div class="alert-warning">
                    <h4>üìà Alta Volatilidade</h4>
                    <p>Vendas com varia√ß√£o de <strong>{fmt_pct(volatility)}</strong> ‚Äî considere estrat√©gias de estabiliza√ß√£o.</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                f"""
                <div class="alert-success">
                    <h4>üéØ Performance Consistente</h4>
                    <p>Padr√£o sazonal: <strong>{seasonality}</strong></p>
                </div>
                """,
                unsafe_allow_html=True,
            )


def display_comparative_analysis(k: Dict[str, Any], df_f: pd.DataFrame) -> None:
    """Exibe an√°lises comparativas entre per√≠odos e indicadores derivados.

    Gera um gr√°fico de barras comparando faturamento do per√≠odo atual com o
    per√≠odo anterior e um indicador tipo gauge para a correla√ß√£o entre
    pedidos e faturamento.

    Args:
        k: Dicion√°rio de KPIs retornado por `compute_kpis`.
        df_f: DataFrame filtrado contendo os dados do per√≠odo atual.
    """
    st.markdown("### üîÑ An√°lise Comparativa Detalhada")
    comp_col1, comp_col2 = st.columns(2)

    current_fat = k["period_sum"]["fat"]
    prev_fat = k["prev_period_fat"]

    with comp_col1:
        fig_comp = go.Figure()
        fig_comp.add_trace(
            go.Bar(
                x=["Per√≠odo Atual", "Per√≠odo Anterior"],
                y=[current_fat, prev_fat],
                marker_color=[theme_colors["primary"], theme_colors["secondary"]],
                text=[fmt_brl(current_fat), fmt_brl(prev_fat)],
                textposition="auto",
            )
        )
        fig_comp.update_layout(title="Compara√ß√£o de Faturamento", height=300)
        st.plotly_chart(fig_comp, use_container_width=True)

    with comp_col2:
        correlation = k.get("advanced", {}).get("correlation", 0) or 0
        fig_corr = go.Figure(
            go.Indicator(
                mode="gauge+number",
                value=abs(correlation) * 100,
                title={"text": "Correla√ß√£o Pedidos √ó Faturamento"},
                gauge={
                    "axis": {"range": [0, 100]},
                    "bar": {"color": theme_colors["primary"]},
                    "steps": [
                        {"range": [0, 50], "color": "#E9ECEF"},
                        {"range": [50, 80], "color": "#CED4DA"},
                        {"range": [80, 100], "color": "#ADB5BD"},
                    ],
                },
            )
        )
        fig_corr.update_layout(height=300)
        st.plotly_chart(fig_corr, use_container_width=True)


def display_predictive_analysis(k: Dict[str, Any], show_forecasts: bool) -> None:
    """Mostra an√°lise preditiva de faturamento utilizando Holt-Winters.

    Caso a op√ß√£o de mostrar previs√µes esteja habilitada e existam pelo menos
    12 meses de dados, a fun√ß√£o ajusta um modelo `ExponentialSmoothing` para
    gerar proje√ß√µes. Tamb√©m exibe m√©tricas resumidas da previs√£o.

    Args:
        k: Dicion√°rio de KPIs e s√©ries temporais.
        show_forecasts: Flag indicando se as previs√µes devem ser exibidas.
    """
    st.markdown("### üîÆ An√°lise Preditiva")
    if not show_forecasts:
        st.info("Ative a op√ß√£o 'Mostrar previs√µes' para ver a proje√ß√£o de faturamento.")
        return

    serie_temporal: Optional[pd.DataFrame] = k.get("serie_temporal")
    if sm is None or ExponentialSmoothing is None or serie_temporal is None or len(serie_temporal) < 12:
        st.info("Previs√µes requerem pelo menos 12 meses de dados e a biblioteca statsmodels.")
        return

    # Controles locais para previs√£o
    forecast_periods: int = st.slider("Per√≠odos de Previs√£o (meses)", 3, 12, 6, key="forecast_periods_slider")
    seasonal_mode: str = st.selectbox("Sazonalidade", ["aditiva", "multiplicativa"], index=0)

    try:
        serie_forecast = serie_temporal.set_index("data")["faturamento"]
        serie_forecast.index = pd.to_datetime(serie_forecast.index)
        serie_forecast = serie_forecast.asfreq("MS")

        model = ExponentialSmoothing(
            serie_forecast,
            seasonal="add" if seasonal_mode == "aditiva" else "mul",
            seasonal_periods=12,
        ).fit()
        forecast = model.forecast(int(forecast_periods))
        forecast_dates = pd.date_range(
            start=serie_forecast.index[-1] + pd.DateOffset(months=1), periods=int(forecast_periods), freq="MS"
        )

        fig_pred = go.Figure()
        fig_pred.add_trace(
            go.Scatter(
                x=serie_forecast.index,
                y=serie_forecast.values,
                mode="lines+markers",
                name="Hist√≥rico",
                line=dict(color=theme_colors["primary"]),
            )
        )
        fig_pred.add_trace(
            go.Scatter(
                x=forecast_dates,
                y=forecast.values,
                mode="lines+markers",
                name="Previs√£o",
                line=dict(color=theme_colors["warning"], dash="dash"),
            )
        )
        fig_pred.update_layout(
            title=f"Previs√£o de Faturamento - Pr√≥ximos {int(forecast_periods)} Meses",
            xaxis_title="Data",
            yaxis_title="Faturamento (R$)",
            height=400,
        )
        st.plotly_chart(fig_pred, use_container_width=True)

        # M√©tricas de previs√£o
        pred_col1, pred_col2, pred_col3 = st.columns(3)
        with pred_col1:
            st.metric("Previs√£o Pr√≥ximo M√™s", fmt_brl(forecast.iloc[0]), help="Modelo Holt‚ÄëWinters")
        with pred_col2:
            st.metric("M√©dia Prevista", fmt_brl(forecast.mean()))
        with pred_col3:
            st.metric("Total Previsto", fmt_brl(forecast.sum()))
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel gerar previs√µes: {e}")


def display_detailed_analysis(df_f: pd.DataFrame, df_lojas: pd.DataFrame, k: Dict[str, Any]) -> None:
    """Apresenta a an√°lise detalhada em diversas abas.

    Inclui a evolu√ß√£o temporal dos indicadores, compara√ß√µes entre lojas,
    an√°lises avan√ßadas de decomposi√ß√£o e correla√ß√£o, benchmarking e um resumo
    para dispositivos m√≥veis. Esta fun√ß√£o √© respons√°vel por montar a maior
    parte das visualiza√ß√µes interativas do dashboard.

    Args:
        df_f: DataFrame filtrado pelo per√≠odo atual.
        df_lojas: DataFrame contendo todos os dados das lojas selecionadas.
        k: Dicion√°rio de m√©tricas gerado por `compute_kpis`.
    """
    st.markdown("### üìà An√°lise Detalhada")
    tabs = st.tabs([
        "üìä Evolu√ß√£o Temporal",
        "üè™ Performance por Loja",
        "üî¨ An√°lise Avan√ßada",
        "üéØ Benchmarking",
        "üì± Mobile Dashboard",
    ])

    # Evolu√ß√£o temporal
    with tabs[0]:
        st.markdown("#### Evolu√ß√£o dos Indicadores no Per√≠odo")
        serie_f = (
            df_f.dropna(subset=["data"]).groupby("data", as_index=False).agg(
                faturamento=("faturamento", "sum"), pedidos=("pedidos", "sum")
            ).sort_values("data")
        )
        if not serie_f.empty:
            serie_f["ticket_medio"] = serie_f.apply(lambda r: safe_div(r["faturamento"], r["pedidos"]), axis=1)
            serie_f["faturamento_mm3"] = serie_f["faturamento"].rolling(window=3, min_periods=1).mean()
            serie_f["faturamento_mm6"] = serie_f["faturamento"].rolling(window=6, min_periods=1).mean()

            fig_evolution = make_subplots(
                rows=2,
                cols=2,
                subplot_titles=(
                    "Faturamento e M√©dias M√≥veis",
                    "Pedidos",
                    "Ticket M√©dio",
                    "Crescimento MoM",
                ),
                specs=[[{"secondary_y": True}, {"secondary_y": False}], [{"secondary_y": False}, {"secondary_y": False}]],
            )
            # Faturamento e m√©dias m√≥veis
            fig_evolution.add_trace(
                go.Scatter(
                    x=serie_f["data"],
                    y=serie_f["faturamento"],
                    name="Faturamento",
                    mode="lines+markers",
                    line=dict(width=3, color=theme_colors["primary"]),
                ),
                row=1,
                col=1,
            )
            fig_evolution.add_trace(
                go.Scatter(
                    x=serie_f["data"],
                    y=serie_f["faturamento_mm3"],
                    name="MM 3M",
                    mode="lines",
                    line=dict(width=2, dash="dot", color=theme_colors["info"]),
                ),
                row=1,
                col=1,
            )
            fig_evolution.add_trace(
                go.Scatter(
                    x=serie_f["data"],
                    y=serie_f["faturamento_mm6"],
                    name="MM 6M",
                    mode="lines",
                    line=dict(width=2, dash="dash", color=theme_colors["success"]),
                ),
                row=1,
                col=1,
            )
            # Pedidos
            fig_evolution.add_trace(
                go.Bar(
                    x=serie_f["data"],
                    y=serie_f["pedidos"],
                    name="Pedidos",
                    marker_color=theme_colors["secondary"],
                ),
                row=1,
                col=2,
            )
            # Ticket m√©dio
            fig_evolution.add_trace(
                go.Scatter(
                    x=serie_f["data"],
                    y=serie_f["ticket_medio"],
                    name="Ticket M√©dio",
                    mode="lines+markers",
                    line=dict(width=2, color=theme_colors["warning"]),
                ),
                row=2,
                col=1,
            )
            # Crescimento MoM
            if len(serie_f) > 1:
                serie_f["growth_mom"] = serie_f["faturamento"].pct_change()
                fig_evolution.add_trace(
                    go.Bar(
                        x=serie_f["data"],
                        y=serie_f["growth_mom"],
                        name="Crescimento MoM",
                        marker_color=[
                            theme_colors["danger"] if x < 0 else theme_colors["success"] for x in serie_f["growth_mom"]
                        ],
                    ),
                    row=2,
                    col=2,
                )
            fig_evolution.update_layout(height=600, showlegend=True)
            st.plotly_chart(fig_evolution, use_container_width=True)

            # Estat√≠sticas resumo
            stats_col1, stats_col2, stats_col3, stats_col4 = st.columns(4)
            with stats_col1:
                st.metric("M√©dia Mensal", fmt_brl(serie_f["faturamento"].mean()))
            with stats_col2:
                st.metric("Mediana", fmt_brl(serie_f["faturamento"].median()))
            with stats_col3:
                st.metric("Desvio Padr√£o", fmt_brl(serie_f["faturamento"].std()))
            with stats_col4:
                coef_var = serie_f["faturamento"].std() / max(1e-9, serie_f["faturamento"].mean())
                st.metric("Coef. Varia√ß√£o", fmt_pct(coef_var))

    # Performance por loja
    with tabs[1]:
        st.markdown("#### An√°lise Comparativa entre Lojas")
        if not df_f.empty:
            vis_col1, vis_col2 = st.columns([1, 1])
            with vis_col1:
                st.markdown("**Contribui√ß√£o no Faturamento (Treemap)**")
                part = df_f.groupby("loja", as_index=False)["faturamento"].sum()
                if not part.empty:
                    fig_tree = px.treemap(
                        part,
                        path=["loja"],
                        values="faturamento",
                        title="Participa√ß√£o de cada loja no faturamento do per√≠odo",
                        color="faturamento",
                        color_continuous_scale="Viridis",
                    )
                    fig_tree.update_layout(height=400)
                    st.plotly_chart(fig_tree, use_container_width=True)
            with vis_col2:
                st.markdown("**Efici√™ncia (Faturamento vs. Pedidos)**")
                eff = df_f.groupby("loja", as_index=False).agg(
                    faturamento=("faturamento", "sum"), pedidos=("pedidos", "sum")
                )
                if not eff.empty and eff["pedidos"].sum() > 0:
                    eff["ticket"] = eff["faturamento"] / eff["pedidos"].replace(0, np.nan)
                    eff["ticket"].fillna(0.0, inplace=True)
                    fig_eff = px.scatter(
                        eff,
                        x="pedidos",
                        y="faturamento",
                        size="ticket",
                        color="loja",
                        hover_name="loja",
                        size_max=60,
                        title="Efici√™ncia da Loja no Per√≠odo",
                        color_discrete_sequence=custom_colors,
                    )
                    fig_eff.update_layout(height=400)
                    st.plotly_chart(fig_eff, use_container_width=True)

            # Ranking de lojas (tabela)
            st.markdown("**Ranking de Performance**")
            ranking_data = df_f.groupby("loja", as_index=False).agg({"faturamento": "sum", "pedidos": "sum"})
            ranking_data["ticket_medio"] = ranking_data["faturamento"] / ranking_data["pedidos"].replace(0, np.nan)
            ranking_data["ticket_medio"].fillna(0.0, inplace=True)
            ranking_data["participacao"] = ranking_data["faturamento"] / max(1e-9, ranking_data["faturamento"].sum())
            ranking_data = ranking_data.sort_values("faturamento", ascending=False)

            ranking_display = ranking_data.copy()
            ranking_display["faturamento"] = ranking_display["faturamento"].apply(fmt_brl)
            ranking_display["pedidos"] = ranking_display["pedidos"].apply(fmt_int)
            ranking_display["ticket_medio"] = ranking_display["ticket_medio"].apply(fmt_brl)
            ranking_display["participacao"] = ranking_display["participacao"].apply(lambda x: fmt_pct(x, 2))

            st.dataframe(
                ranking_display.rename(
                    columns={
                        "loja": "Loja",
                        "faturamento": "Faturamento",
                        "pedidos": "Pedidos",
                        "ticket_medio": "Ticket M√©dio",
                        "participacao": "Participa√ß√£o %",
                    }
                ),
                use_container_width=True,
                height=300,
            )

            # Heatmap
            st.markdown("**Desempenho Mensal por Loja (Heatmap)**")
            heatmap_data = (
                df_f.pivot_table(index="loja", columns="periodo", values="faturamento", aggfunc="sum").fillna(0)
            )
            if not heatmap_data.empty:
                fig_heatmap = go.Figure(
                    data=go.Heatmap(
                        z=heatmap_data.values,
                        x=heatmap_data.columns,
                        y=heatmap_data.index,
                        colorscale="RdYlGn",
                        hoverongaps=False,
                    )
                )
                fig_heatmap.update_layout(title="Faturamento Mensal por Loja", xaxis_nticks=36, height=500)
                st.plotly_chart(fig_heatmap, use_container_width=True)

    # An√°lise avan√ßada
    with tabs[2]:
        st.markdown("#### An√°lise de S√©rie Temporal e Correla√ß√µes")
        serie_all = df_lojas.groupby("data")["faturamento"].sum().sort_index()
        analysis_tabs = st.tabs(["Decomposi√ß√£o", "Correla√ß√µes", "Distribui√ß√µes"])

        # Decomposi√ß√£o
        with analysis_tabs[0]:
            if len(serie_all) >= 24 and sm is not None:
                try:
                    s = serie_all.copy()
                    s.index = pd.to_datetime(s.index)
                    res = sm.tsa.seasonal_decompose(s.asfreq("MS"), model="additive")
                    fig_decomp = make_subplots(
                        rows=4,
                        cols=1,
                        shared_xaxes=True,
                        subplot_titles=("Original", "Tend√™ncia", "Sazonalidade", "Res√≠duos"),
                    )
                    fig_decomp.add_trace(
                        go.Scatter(x=res.observed.index, y=res.observed, mode="lines", name="Original", line=dict(color=theme_colors["primary"])),
                        row=1,
                        col=1,
                    )
                    fig_decomp.add_trace(
                        go.Scatter(x=res.trend.index, y=res.trend, mode="lines", name="Tend√™ncia", line=dict(color=theme_colors["success"])),
                        row=2,
                        col=1,
                    )
                    fig_decomp.add_trace(
                        go.Scatter(x=res.seasonal.index, y=res.seasonal, mode="lines", name="Sazonalidade", line=dict(color=theme_colors["warning"])),
                        row=3,
                        col=1,
                    )
                    fig_decomp.add_trace(
                        go.Scatter(x=res.resid.index, y=res.resid, mode="markers", name="Res√≠duos", marker=dict(color=theme_colors["info"])),
                        row=4,
                        col=1,
                    )
                    fig_decomp.update_layout(height=700, showlegend=False)
                    st.plotly_chart(fig_decomp, use_container_width=True)
                    st.markdown(
                        """
                        **Interpreta√ß√£o da Decomposi√ß√£o:**
                        - **Tend√™ncia**: dire√ß√£o geral do faturamento (crescimento/decl√≠nio)
                        - **Sazonalidade**: padr√µes recorrentes (ex.: mensais/anuais)
                        - **Res√≠duos**: varia√ß√µes n√£o explicadas pela tend√™ncia/sazonalidade
                        """
                    )
                except Exception as e:
                    st.warning(f"Erro na decomposi√ß√£o: {e}")
            else:
                st.info("A decomposi√ß√£o requer pelo menos 24 meses de dados e statsmodels instalado.")

        # Correla√ß√µes
        with analysis_tabs[1]:
            if len(df_lojas) > 10:
                corr_data = (
                    df_lojas.pivot_table(index="data", columns="loja", values="faturamento", aggfunc="sum").fillna(0)
                )
                if corr_data.shape[1] > 1:
                    correlation_matrix = corr_data.corr()
                    fig_corr_matrix = go.Figure(
                        data=go.Heatmap(
                            z=correlation_matrix.values,
                            x=correlation_matrix.columns,
                            y=correlation_matrix.index,
                            colorscale="RdBu",
                            zmid=0,
                        )
                    )
                    fig_corr_matrix.update_layout(title="Matriz de Correla√ß√£o entre Lojas", height=500)
                    st.plotly_chart(fig_corr_matrix, use_container_width=True)

                    # Top correla√ß√µes
                    st.markdown("**Maiores Correla√ß√µes:**")
                    corr_pairs: List[Dict[str, Any]] = []
                    cols = list(correlation_matrix.columns)
                    for i in range(len(cols)):
                        for j in range(i + 1, len(cols)):
                            corr_pairs.append({"Loja 1": cols[i], "Loja 2": cols[j], "Correla√ß√£o": correlation_matrix.iloc[i, j]})
                    top_corr = pd.DataFrame(corr_pairs).sort_values("Correla√ß√£o", ascending=False).head(5)
                    top_corr["Correla√ß√£o"] = top_corr["Correla√ß√£o"].apply(lambda x: f"{x:.3f}")
                    st.dataframe(top_corr, use_container_width=True)

        # Distribui√ß√µes
        with analysis_tabs[2]:
            fig_dist = make_subplots(rows=1, cols=2, subplot_titles=["Distribui√ß√£o do Faturamento", "Box Plot por Loja"])
            fig_dist.add_trace(
                go.Histogram(x=df_f["faturamento"], nbinsx=30, name="Distribui√ß√£o", marker_color=theme_colors["primary"]),
                row=1,
                col=1,
            )
            fig_dist.add_trace(
                go.Box(y=df_f["faturamento"], x=df_f["loja"], name="Box Plot", marker_color=theme_colors["secondary"]),
                row=1,
                col=2,
            )
            fig_dist.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig_dist, use_container_width=True)

    # Benchmarking
    with tabs[3]:
        st.markdown("#### Benchmarking e Compara√ß√µes")
        bench_metrics = df_f.groupby("loja").agg({
            "faturamento": ["sum", "mean", "std"],
            "pedidos": ["sum", "mean"],
            "ticket": "mean",
        }).round(2)
        bench_metrics.columns = ["Fat_Total", "Fat_M√©dio", "Fat_StdDev", "Ped_Total", "Ped_M√©dio", "Ticket_M√©dio"]

        # Calcula scores normalizados para cada m√©trica
        for col in ["Fat_Total", "Fat_M√©dio", "Ped_Total", "Ticket_M√©dio"]:
            if col in bench_metrics.columns and bench_metrics[col].max() > 0:
                bench_metrics[f"{col}_Score"] = (bench_metrics[col] / bench_metrics[col].max()) * 100

        score_cols = [c for c in bench_metrics.columns if c.endswith("_Score")]
        if score_cols:
            bench_metrics["Score_Geral"] = bench_metrics[score_cols].mean(axis=1).round(1)
            top_5_lojas = bench_metrics.nlargest(5, "Score_Geral")

            fig_radar = go.Figure()
            theta = ["Faturamento Total", "Faturamento M√©dio", "Total Pedidos", "Ticket M√©dio"]
            for idx, (loja, row) in enumerate(top_5_lojas.iterrows()):
                fig_radar.add_trace(
                    go.Scatterpolar(
                        r=[
                            row.get("Fat_Total_Score", 0),
                            row.get("Fat_M√©dio_Score", 0),
                            row.get("Ped_Total_Score", 0),
                            row.get("Ticket_M√©dio_Score", 0),
                        ],
                        theta=theta,
                        fill="toself",
                        name=loja,
                        marker_color=custom_colors[idx % len(custom_colors)],
                    )
                )
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
                showlegend=True,
                title="Benchmarking - Top 5 Lojas",
                height=500,
            )
            st.plotly_chart(fig_radar, use_container_width=True)

            st.markdown("**Ranking Geral de Performance:**")
            ranking_display = bench_metrics[["Score_Geral"]].sort_values("Score_Geral", ascending=False)
            ranking_display["Posi√ß√£o"] = range(1, len(ranking_display) + 1)
            ranking_display = ranking_display[["Posi√ß√£o", "Score_Geral"]].reset_index().rename(
                columns={"index": "Loja", "Score_Geral": "Score"}
            )
            st.dataframe(ranking_display, use_container_width=True)

    # Mobile Dashboard
    with tabs[4]:
        st.markdown("#### Dashboard Mobile (Resumo)")
        mobile_col1, mobile_col2 = st.columns(2)
        with mobile_col1:
            st.metric("üí∞ Faturamento", fmt_brl(k["period_sum"]["fat"]))
            st.metric("üõí Pedidos", fmt_int(k["period_sum"]["ped"]))
            st.metric("üéØ Ticket M√©dio", fmt_brl(k["period_sum"]["tik"]))
        with mobile_col2:
            if k.get("advanced"):
                st.metric("üìä Crescimento", fmt_pct(k["advanced"].get("growth_rate", 0)))
                st.metric("‚ö° Efici√™ncia", fmt_pct(k["advanced"].get("efficiency", 0)))
                st.metric("üìà vs AA", fmt_pct(k.get("delta_yoy_fat", 0)))
        if not df_f.empty:
            serie_f_mobile = (
                df_f.dropna(subset=["data"]).groupby("data", as_index=False).agg(faturamento=("faturamento", "sum")).sort_values("data")
            )
            fig_mobile = px.line(x=serie_f_mobile["data"], y=serie_f_mobile["faturamento"], title="Evolu√ß√£o do Faturamento")
            fig_mobile.update_layout(height=300)
            st.plotly_chart(fig_mobile, use_container_width=True)


def display_top_performers(
    df: pd.DataFrame,
    periodo_ini: str,
    periodo_fim: str,
    *,
    top_n: int = 3,
    show_podium: bool = True,
) -> None:
    """Exibe rankings de desempenho e p√≥dio por m√©trica.

    A fun√ß√£o apresenta um ranking Top‚ÄëN baseado no n√∫mero de pedidos e um
    p√≥dio por tr√™s categorias: Faturamento, Pedidos e Ticket M√©dio.

    Args:
        df: DataFrame original com todos os registros.
        periodo_ini: In√≠cio do per√≠odo selecionado.
        periodo_fim: Fim do per√≠odo selecionado.
        top_n: Quantidade de lojas a serem exibidas no ranking.
        show_podium: Indica se o p√≥dio por categoria deve ser exibido.
    """
    st.markdown("### üèÜ Top Performers do Per√≠odo")

    required_cols = {"periodo", "loja", "pedidos", "faturamento"}
    if not required_cols.issubset(df.columns):
        missing = required_cols - set(df.columns)
        st.warning(f"Faltam colunas para esta se√ß√£o: {', '.join(sorted(missing))}")
        return

    mask = (df["periodo"] >= periodo_ini) & (df["periodo"] <= periodo_fim)
    base = df.loc[mask, ["loja", "periodo", "pedidos", "faturamento"]].copy()

    if base.empty or base["pedidos"].notna().sum() == 0:
        st.info("Nenhum dado v√°lido para o per√≠odo selecionado.")
        return

    agg = (
        base.dropna(subset=["loja"]).groupby("loja", as_index=False).agg(
            faturamento=("faturamento", "sum"), pedidos=("pedidos", "sum")
        )
    )
    agg["ticket"] = agg["faturamento"] / agg["pedidos"].replace(0, np.nan)
    agg["ticket"].fillna(0.0, inplace=True)

    # Ranking top‚ÄëN por pedidos
    rank = agg.sort_values("pedidos", ascending=False).head(max(1, min(top_n, len(agg))))
    if not rank.empty:
        cols = st.columns(len(rank))
        total_ped = int(agg["pedidos"].sum()) if pd.notna(agg["pedidos"].sum()) else 0
        medals = ["ü•á", "ü•à", "ü•â"]
        for i, (_, row) in enumerate(rank.reset_index(drop=True).iterrows()):
            pct = (row["pedidos"] / total_ped * 100) if total_ped else 0.0
            pos = medals[i] if i < len(medals) else f"{i+1}¬∫"
            with cols[i]:
                st.markdown(
                    f"""
                    <div class="metric-card">
                        <h3>{pos} {row['loja']}</h3>
                        <p><strong>{fmt_int(row['pedidos'])}</strong> pedidos</p>
                        <p>{pct:.1f}% do total</p>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

    # P√≥dio por m√©trica
    if show_podium and not agg.empty:
        def _top_row(col: str) -> Optional[pd.Series]:
            s = agg[col]
            return agg.loc[s.idxmax()] if s.notna().any() else None

        top_fat_row = _top_row("faturamento")
        top_ped_row = _top_row("pedidos")
        top_tkt_row = _top_row("ticket")

        metrics_data: List[Tuple[str, str, float, str]] = []
        if top_fat_row is not None:
            metrics_data.append(("Faturamento", str(top_fat_row["loja"]), float(top_fat_row["faturamento"]), "üí∞"))
        if top_ped_row is not None:
            metrics_data.append(("Pedidos", str(top_ped_row["loja"]), float(top_ped_row["pedidos"]), "üõí"))
        if top_tkt_row is not None:
            metrics_data.append(("Ticket", str(top_tkt_row["loja"]), float(top_tkt_row["ticket"]), "üé´"))

        if metrics_data:
            order = {"Faturamento": 1, "Pedidos": 2, "Ticket": 3}
            metrics_data.sort(key=lambda x: order.get(x[0], 99))
            html: List[str] = ['<div class="podium-container">']
            for metric, loja, valor, icon in metrics_data:
                cls = "podium-item first" if metric == "Faturamento" else "podium-item"
                val_fmt = fmt_brl(valor) if metric in ("Faturamento", "Ticket") else fmt_int(valor)
                html.append(
                    f"""
                    <div class="{cls}">
                        <h4>{icon} {metric}</h4>
                        <p><strong>{loja}</strong></p>
                        <p>{val_fmt}</p>
                    </div>
                    """
                )
            html.append("</div>")
            st.markdown("#### P√≥dio por Categoria")
            st.markdown("".join(html), unsafe_allow_html=True)


def display_insights(k: Dict[str, Any]) -> List[str]:
    """Gera e exibe lista de insights e recomenda√ß√µes baseados nas m√©tricas.

    Interpreta os valores de crescimento, volatilidade, efici√™ncia, sazonalidade
    e correla√ß√£o para apresentar mensagens propositivas que auxiliam na
    tomada de decis√£o.

    Args:
        k: Dicion√°rio de m√©tricas retornado por `compute_kpis`.

    Returns:
        Lista de strings com recomenda√ß√µes geradas.
    """
    st.markdown("### üí° Insights e Recomenda√ß√µes")
    insights: List[str] = []
    adv = k.get("advanced", {})
    growth_rate = adv.get("growth_rate", 0)
    volatility = adv.get("volatility", 0)
    efficiency = adv.get("efficiency", 0)
    seasonality = adv.get("seasonality", "")
    correlation = adv.get("correlation", 0) or 0

    if growth_rate > 0.03:
        insights.append("‚úÖ **Crescimento Acelerado**: Considere expandir opera√ß√µes nas lojas top performers.")
    elif growth_rate < -0.02:
        insights.append("‚ö†Ô∏è **Decl√≠nio Preocupante**: Revise estrat√©gias de marketing e opera√ß√µes.")

    if volatility > 0.25:
        insights.append("üìä **Alta Volatilidade**: Implemente estrat√©gias de estabiliza√ß√£o de demanda.")

    if efficiency > 0.10:
        insights.append("‚ö° **Excelente Efici√™ncia**: Modelo operacional pode ser replicado em outras lojas.")
    elif efficiency < -0.10:
        insights.append("üîß **Baixa Efici√™ncia**: Revisar processos operacionais e treinamento de equipe.")

    if seasonality == "Alta sazonalidade":
        insights.append("üìÖ **Forte Sazonalidade**: Planeje estoques e promo√ß√µes baseadas em padr√µes mensais.")

    if abs(correlation) > 0.80:
        insights.append("üîó **Alta Correla√ß√£o**: Estrat√©gias unificadas podem ser eficazes.")
    elif abs(correlation) < 0.50:
        insights.append("üéØ **Baixa Correla√ß√£o**: Considere estrat√©gias personalizadas por loja.")

    if insights:
        for item in insights:
            st.markdown(item)
    else:
        st.info("üìä Performance est√°vel no per√≠odo analisado.")
    return insights


# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main() -> None:
    """Fun√ß√£o principal que orquestra todo o fluxo do dashboard.

    Esta fun√ß√£o inicializa a configura√ß√£o, carrega dados, aplica filtros,
    computa KPIs, chama componentes de interface e gerencia a barra lateral
    com utilidades adicionais. √â a fun√ß√£o invocada quando a aplica√ß√£o √©
    executada diretamente.
    """
    configure_page()
    df = load_data()

    (
        analysis_mode,
        periodo_ini,
        periodo_fim,
        sel_lojas,
        include_weekends,  # reservado para uso futuro
        show_trends,       # reservado para uso futuro
        show_forecasts,
    ) = prepare_filters(df)

    df_f, df_lojas = filter_data(df, periodo_ini, periodo_fim, sel_lojas)
    k = compute_kpis(df_f, df_lojas, periodo_ini, periodo_fim)

    # Cabe√ßalho
    display_header(periodo_ini, periodo_fim, sel_lojas, analysis_mode)

    # Painel de indicadores
    display_kpi_panel(k)

    # Alertas
    display_alerts(k)

    # Modos espec√≠ficos
    if analysis_mode == "Comparativo":
        display_comparative_analysis(k, df_f)
    elif analysis_mode == "Preditivo":
        display_predictive_analysis(k, show_forecasts)

    # An√°lise detalhada (sempre dispon√≠vel)
    display_detailed_analysis(df_f, df_lojas, k)

    # Top performers
    display_top_performers(df, periodo_ini, periodo_fim)

    # Insights finais
    _ = display_insights(k)

    # Sidebar extra (utilidades)
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Informa√ß√µes")
        st.caption(f"√öltima atualiza√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
        st.caption(f"Total de registros: {len(df):,}")
        periodos = sorted(p for p in df["periodo"].dropna().unique().tolist())
        if periodos:
            st.caption(f"Per√≠odo dos dados: {periodos[0]} a {periodos[-1]}")

        if st.button("üîÑ Limpar Cache"):
            st.cache_data.clear()
            st.success("Cache limpo com sucesso!")
            st.rerun()

        st.markdown("---")
        st.caption(
            "üí° **Dica**: Use os filtros para focar em per√≠odos espec√≠ficos e lojas de interesse. O modo 'Preditivo' oferece proje√ß√µes baseadas em s√©rie temporal (Holt‚ÄëWinters)."
        )

    st.success("‚úÖ Dashboard carregado com sucesso! Explore as abas e modos para insights detalhados.")


if __name__ == "__main__":
    main()
    """
Dashboard Inteligente Modularizado (v3.0) - Vers√£o Otimizada
=============================================================

Vers√£o melhorada com:
- KPIs inteligentes com explica√ß√µes interativas
- Top Performers com visualiza√ß√µes aprimoradas
- Algoritmos de an√°lise avan√ßada (clustering, outliers, tend√™ncias)
- Interface mais visual e informativa
- Componentes modulares e reutiliz√°veis
- Performance otimizada com caching inteligente
"""

from __future__ import annotations

import os
import re
import unicodedata
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import warnings

warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from scipy.stats import pearsonr, zscore

# Tentativa de importa√ß√£o dos m√≥dulos de clustering. Caso n√£o estejam dispon√≠veis,
# definimos indicadores nulos para evitar erros de importa√ß√£o.
try:
    from sklearn.cluster import KMeans  # type: ignore
    from sklearn.preprocessing import StandardScaler  # type: ignore
    HAS_SKLEARN = True
except ImportError:
    KMeans = None  # type: ignore
    StandardScaler = None  # type: ignore
    HAS_SKLEARN = False

from typing import Optional, Any, Dict, Tuple, List, Sequence

# Statsmodels com fallback
try:
    import statsmodels.api as sm
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    from statsmodels.stats.diagnostic import acorr_ljungbox
    HAS_STATSMODELS = True
except ImportError:
    sm = None
    ExponentialSmoothing = None
    HAS_STATSMODELS = False

# =============================================================================
# CONFIGURA√á√ïES AVAN√áADAS E CONSTANTES
# =============================================================================

# Constantes de neg√≥cio
BENCHMARK_TARGETS = {
    "growth_rate_excellent": 0.05,
    "growth_rate_good": 0.02,
    "volatility_high": 0.30,
    "volatility_moderate": 0.15,
    "efficiency_excellent": 0.15,
    "efficiency_good": 0.05,
    "correlation_strong": 0.70,
    "outlier_zscore": 2.0,
}

# Paletas de cores avan√ßadas
COLOR_SCHEMES = {
    "primary": ["#FF6B35", "#004E89", "#28A745", "#FFC107", "#DC3545", "#17A2B8"],
    "performance": ["#2E8B57", "#FFD700", "#FF4500", "#8B0000"],
    "gradient": ["#667eea", "#764ba2", "#f093fb", "#f5576c"],
    "business": ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b"],
}

def configure_advanced_page() -> None:
    """Configura√ß√£o avan√ßada da p√°gina com tema personalizado."""
    st.set_page_config(
        page_title="Dashboard Inteligente v3.0 ‚Äî An√°lise Avan√ßada",
        page_icon="üìä",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            "Get Help": "https://www.streamlit.io/community",
            "Report a bug": "mailto:dashboard@empresa.com",
            "About": "### Dashboard Inteligente v3.0\nAn√°lise avan√ßada com ML e visualiza√ß√µes interativas.",
        },
    )

    # CSS avan√ßado com anima√ß√µes e componentes modernos
    st.markdown(
        """
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        
        .main { font-family: 'Inter', sans-serif; }
        
        .hero-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem; border-radius: 15px; color: white;
            text-align: center; margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        
        .kpi-card {
            background: white; padding: 1.5rem; border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border-left: 4px solid #667eea;
            transition: transform 0.2s ease-in-out;
        }
        .kpi-card:hover { transform: translateY(-2px); }
        
        .insight-card {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white; padding: 1rem; border-radius: 10px;
            margin: 0.5rem 0; box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        
        .top-performer-gold {
            background: linear-gradient(135deg, #FFD700 0%, #FFA500 100%);
            color: #333; padding: 1.5rem; border-radius: 12px;
            text-align: center; box-shadow: 0 8px 25px rgba(255,215,0,0.3);
            border: 2px solid #FFD700; position: relative;
        }
        
        .top-performer-silver {
            background: linear-gradient(135deg, #C0C0C0 0%, #A8A8A8 100%);
            color: #333; padding: 1.5rem; border-radius: 12px;
            text-align: center; box-shadow: 0 6px 20px rgba(192,192,192,0.3);
            border: 2px solid #C0C0C0;
        }
        
        .top-performer-bronze {
            background: linear-gradient(135deg, #CD7F32 0%, #B8860B 100%);
            color: white; padding: 1.5rem; border-radius: 12px;
            text-align: center; box-shadow: 0 6px 20px rgba(205,127,50,0.3);
            border: 2px solid #CD7F32;
        }
        
        .metric-explanation {
            background: #f8f9fa; border-left: 4px solid #007bff;
            padding: 1rem; border-radius: 8px; margin: 1rem 0;
        }
        
        .progress-bar {
            background: #e9ecef; border-radius: 10px; overflow: hidden;
            height: 20px; margin: 0.5rem 0;
        }
        
        .progress-fill {
            height: 100%; background: linear-gradient(90deg, #28a745, #20c997);
            transition: width 0.5s ease-in-out;
        }
        
        .alert-success { background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); }
        .alert-warning { background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); }
        .alert-danger { background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); }
        
        .performance-badge {
            display: inline-block; padding: 0.25rem 0.75rem;
            border-radius: 20px; font-size: 0.875rem; font-weight: 500;
        }
        .badge-excellent { background: #28a745; color: white; }
        .badge-good { background: #ffc107; color: #212529; }
        .badge-poor { background: #dc3545; color: white; }
        
        .interactive-tooltip {
            background: #333; color: white; padding: 0.5rem;
            border-radius: 5px; font-size: 0.8rem; position: relative;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

# =============================================================================
# FUN√á√ïES AUXILIARES OTIMIZADAS
# =============================================================================

def normalize_col(name: str) -> str:
    """Normaliza nomes de colunas de forma mais robusta."""
    name = str(name).strip().lower()
    name = "".join(c for c in unicodedata.normalize("NFKD", name) if not unicodedata.combining(c))
    name = re.sub(r"[^\w\s]", "", name)
    return re.sub(r"\s+", "_", name)

def calculate_percentile_rank(value: float, series: pd.Series) -> float:
    """Calcula o percentil de um valor dentro de uma s√©rie."""
    if pd.isna(value) or series.empty:
        return 0.0
    return float((series <= value).sum() / len(series) * 100)

def detect_outliers(series: pd.Series, method: str = "zscore") -> pd.Series:
    """Detecta outliers usando Z-score ou IQR."""
    if method == "zscore":
        z_scores = np.abs(zscore(series.dropna()))
        return pd.Series(z_scores > BENCHMARK_TARGETS["outlier_zscore"], index=series.dropna().index)
    elif method == "iqr":
        Q1, Q3 = series.quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        return (series < lower_bound) | (series > upper_bound)
    return pd.Series(False, index=series.index)

def classify_performance(value: float, metric_type: str) -> Tuple[str, str, str]:
    """Classifica performance e retorna (classe, badge_class, icon)."""
    thresholds = {
        "growth": (BENCHMARK_TARGETS["growth_rate_excellent"], BENCHMARK_TARGETS["growth_rate_good"]),
        "efficiency": (BENCHMARK_TARGETS["efficiency_excellent"], BENCHMARK_TARGETS["efficiency_good"]),
        "volatility": (BENCHMARK_TARGETS["volatility_moderate"], BENCHMARK_TARGETS["volatility_high"]),
    }
    
    if metric_type in thresholds:
        excellent, good = thresholds[metric_type]
        if metric_type == "volatility":  # Menor √© melhor
            if value <= excellent:
                return "Excelente", "badge-excellent", "üü¢"
            elif value <= good:
                return "Bom", "badge-good", "üü°"
            else:
                return "Aten√ß√£o", "badge-poor", "üî¥"
        else:  # Maior √© melhor
            if value >= excellent:
                return "Excelente", "badge-excellent", "üü¢"
            elif value >= good:
                return "Bom", "badge-good", "üü°"
            else:
                return "Aten√ß√£o", "badge-poor", "üî¥"
    
    return "Neutro", "badge-good", "‚ö™"

# =============================================================================
# CARREGAMENTO E PROCESSAMENTO DE DADOS
# =============================================================================

@st.cache_data(ttl=3600, max_entries=10, show_spinner=False)
def load_enhanced_data() -> pd.DataFrame:
    """Carrega dados com valida√ß√µes e enriquecimento autom√°tico."""
    
    def _enhance_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """Enriquece DataFrame com colunas calculadas."""
        # Normaliza√ß√£o de colunas
        df.columns = [normalize_col(c) for c in df.columns]
        
        # Mapeamento de aliases
        aliases = {
            "mes": ["mes", "m√™s", "month", "mm"],
            "ano": ["ano", "year", "yyyy", "aa"],
            "loja": ["loja", "filial", "store", "unidade"],
            "faturamento": ["faturamento", "receita", "vendas", "valor_total", "revenue"],
            "pedidos": ["pedidos", "qtde_pedidos", "qtd_pedidos", "orders", "quantidade"],
            "ticket": ["ticket", "ticket_medio", "ticket_m√©dio", "average_order"],
        }
        
        rename_dict = {}
        for target, variations in aliases.items():
            for col in df.columns:
                if col in variations and target not in df.columns:
                    rename_dict[col] = target
                    break
        
        df = df.rename(columns=rename_dict)
        
        # Convers√µes e valida√ß√µes
        if "mes" in df.columns:
            df["mes"] = pd.to_numeric(df["mes"], errors="coerce").astype("Int64")
        if "ano" in df.columns:
            df["ano"] = pd.to_numeric(df["ano"], errors="coerce").astype("Int64")
        if "faturamento" in df.columns:
            df["faturamento"] = pd.to_numeric(df["faturamento"], errors="coerce")
        if "pedidos" in df.columns:
            df["pedidos"] = pd.to_numeric(df["pedidos"], errors="coerce").astype("Int64")
        if "ticket" in df.columns:
            df["ticket"] = pd.to_numeric(df["ticket"], errors="coerce")
        
        # Cria√ß√£o de colunas derivadas
        if "mes" in df.columns and "ano" in df.columns:
            valid_mask = df["ano"].notna() & df["mes"].notna()
            df.loc[valid_mask, "data"] = pd.to_datetime({
                "year": df.loc[valid_mask, "ano"].astype(int),
                "month": df.loc[valid_mask, "mes"].astype(int),
                "day": 1
            }, errors="coerce")
            df["periodo"] = df["data"].dt.strftime("%Y-%m")
            df["trimestre"] = df["data"].dt.quarter
            df["semestre"] = ((df["data"].dt.month - 1) // 6) + 1
            df["dia_semana"] = df["data"].dt.dayofweek
            df["nome_mes"] = df["data"].dt.month_name()
        
        # C√°lculos de ticket se n√£o existir
        if "ticket" not in df.columns and "faturamento" in df.columns and "pedidos" in df.columns:
            df["ticket"] = df["faturamento"] / df["pedidos"].replace(0, np.nan)
        
        # Limpeza final
        df = df.dropna(subset=["data"]).copy()
        
        return df
    
    # Tentativa de carregamento dos arquivos
    for filename in ["Faturamento_tratado.csv", "Faturamento.csv"]:
        if os.path.exists(filename):
            try:
                df = pd.read_csv(filename, sep=None, engine="python")
                return _enhance_dataframe(df)
            except Exception as e:
                st.warning(f"Erro ao carregar {filename}: {e}")
                continue
    
    # Dados sint√©ticos mais realistas
    return generate_enhanced_sample_data()

def generate_enhanced_sample_data() -> pd.DataFrame:
    """Gera dados sint√©ticos mais realistas e variados."""
    np.random.seed(42)
    
    # Configura√ß√£o de lojas com caracter√≠sticas distintas
    lojas_config = {
        "Centro": {"base_fat": 75000, "volatility": 0.15, "growth_trend": 0.02},
        "Shopping Norte": {"base_fat": 85000, "volatility": 0.10, "growth_trend": 0.03},
        "Shopping Sul": {"base_fat": 90000, "volatility": 0.12, "growth_trend": 0.025},
        "Bairro Leste": {"base_fat": 45000, "volatility": 0.25, "growth_trend": 0.01},
        "Bairro Oeste": {"base_fat": 55000, "volatility": 0.20, "growth_trend": 0.015},
        "Aeroporto": {"base_fat": 65000, "volatility": 0.30, "growth_trend": 0.035},
    }
    
    start_date = datetime(2022, 1, 1)
    periods = 36  # 3 anos de dados
    dates = pd.date_range(start_date, periods=periods, freq="MS")
    
    data = []
    for i, date in enumerate(dates):
        for loja, config in lojas_config.items():
            # Fatores de influ√™ncia
            seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * date.month / 12) + 0.1 * np.cos(2 * np.pi * date.month / 6)
            trend_factor = (1 + config["growth_trend"]) ** i
            random_factor = 1 + np.random.normal(0, config["volatility"])
            
            # Eventos especiais (Black Friday, Natal, etc.)
            special_events = {11: 1.5, 12: 1.8, 1: 0.7, 2: 0.8}  # Nov, Dez, Jan, Fev
            event_factor = special_events.get(date.month, 1.0)
            
            # C√°lculo do faturamento
            faturamento = (config["base_fat"] * seasonal_factor * trend_factor * 
                          random_factor * event_factor)
            
            # Pedidos com correla√ß√£o imperfeita
            ticket_base = 35 + np.random.normal(0, 5)
            ticket_base = max(15, ticket_base)  # M√≠nimo de R$ 15
            pedidos = int(max(1, faturamento / ticket_base + np.random.normal(0, 50)))
            ticket_real = faturamento / pedidos
            
            data.append({
                "mes": date.month,
                "ano": date.year,
                "loja": loja,
                "faturamento": round(faturamento, 2),
                "pedidos": pedidos,
                "ticket": round(ticket_real, 2),
                "data": date,
                "periodo": date.strftime("%Y-%m"),
                "trimestre": date.quarter,
                "semestre": ((date.month - 1) // 6) + 1,
            })
    
    return pd.DataFrame(data)

# =============================================================================
# KPIs INTELIGENTES E EXPLICA√á√ïES
# =============================================================================

class IntelligentKPI:
    """Classe para KPIs com explica√ß√µes autom√°ticas e an√°lise inteligente."""
    
    def __init__(self, name: str, value: float, comparison_value: Optional[float] = None,
                 format_func: Optional[callable] = None, icon: str = "üìä"):
        self.name = name
        self.value = value
        self.comparison_value = comparison_value
        self.format_func = format_func or (lambda x: f"{x:,.2f}")
        self.icon = icon
        self.delta = self._calculate_delta()
        self.performance_class = self._classify_performance()
    
    def _calculate_delta(self) -> Optional[float]:
        """Calcula varia√ß√£o percentual."""
        if self.comparison_value and self.comparison_value != 0:
            return (self.value - self.comparison_value) / abs(self.comparison_value)
        return None
    
    def _classify_performance(self) -> Tuple[str, str]:
        """Classifica performance baseada no delta."""
        if self.delta is None:
            return "neutro", "‚ö™"
        elif self.delta > 0.10:
            return "excelente", "üü¢"
        elif self.delta > 0.05:
            return "bom", "üü°"
        elif self.delta > -0.05:
            return "estavel", "üü†"
        else:
            return "atencao", "üî¥"
    
    def get_explanation(self) -> str:
        """Gera explica√ß√£o autom√°tica do KPI."""
        explanations = {
            "Faturamento Total": "Soma de todas as receitas no per√≠odo. Indica o volume financeiro movimentado.",
            "Pedidos Totais": "N√∫mero total de transa√ß√µes realizadas. Reflete o volume operacional.",
            "Ticket M√©dio": "Valor m√©dio por pedido (Faturamento √∑ Pedidos). Indica o valor por transa√ß√£o.",
            "Taxa de Crescimento": "Crescimento m√©dio mensal composto. Mostra a tend√™ncia de evolu√ß√£o.",
            "Volatilidade": "Variabilidade das vendas. Menor valor indica maior previsibilidade.",
            "Efici√™ncia Operacional": "Performance vs. m√©dia hist√≥rica. Maior valor indica melhor efici√™ncia.",
        }
        return explanations.get(self.name, "KPI de an√°lise de performance.")
    
    def render(self) -> None:
        """Renderiza o KPI com explica√ß√£o interativa."""
        delta_text = f"{self.delta*100:+.1f}%" if self.delta else "N/A"
        performance_class, icon = self.performance_class
        
        with st.container():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.metric(
                    label=f"{self.icon} {self.name}",
                    value=self.format_func(self.value),
                    delta=delta_text if self.delta else None,
                )
            with col2:
                if st.button("‚ÑπÔ∏è", key=f"info_{self.name}"):
                    st.info(self.get_explanation())

def compute_advanced_kpis(df_filtered: pd.DataFrame, df_historical: pd.DataFrame) -> Dict[str, Any]:
    """Computa KPIs avan√ßados com an√°lise estat√≠stica."""
    
    # M√©tricas b√°sicas
    total_faturamento = float(df_filtered["faturamento"].sum())
    total_pedidos = int(df_filtered["pedidos"].sum())
    ticket_medio = total_faturamento / max(1, total_pedidos)
    
    # S√©rie temporal para compara√ß√µes
    serie_atual = df_filtered.groupby("data")["faturamento"].sum().sort_index()
    serie_historica = df_historical.groupby("data")["faturamento"].sum().sort_index()
    
    # Compara√ß√µes temporais
    periodo_anterior_valor = 0.0
    if len(serie_historica) > len(serie_atual):
        periodo_anterior = serie_historica.iloc[-(len(serie_atual)*2):-len(serie_atual)]
        if not periodo_anterior.empty:
            periodo_anterior_valor = float(periodo_anterior.sum())
    
    # M√©tricas avan√ßadas
    kpis: Dict[str, IntelligentKPI] = {}
    
    # Taxa de crescimento composto
    if len(serie_atual) > 1:
        growth_rate = ((serie_atual.iloc[-1] / max(1, serie_atual.iloc[0])) ** (1/(len(serie_atual)-1))) - 1
        kpis["growth_rate"] = IntelligentKPI(
            "Taxa de Crescimento", growth_rate, 0.02, lambda x: f"{x*100:+.2f}%", "üìà"
        )
    
    # Volatilidade (coeficiente de varia√ß√£o)
    if len(serie_atual) > 1:
        cv = serie_atual.std() / max(1e-9, serie_atual.mean())
        kpis["volatility"] = IntelligentKPI(
            "Volatilidade", cv, BENCHMARK_TARGETS["volatility_moderate"], 
            lambda x: f"{x*100:.1f}%", "üìä"
        )
    
    # Efici√™ncia vs hist√≥rico
    ticket_historico = df_historical["faturamento"].sum() / max(1, df_historical["pedidos"].sum())
    eficiencia = (ticket_medio / max(1, ticket_historico)) - 1
    kpis["efficiency"] = IntelligentKPI(
        "Efici√™ncia Operacional", eficiencia, 0.0, lambda x: f"{x*100:+.1f}%", "‚ö°"
    )
    
    # Consist√™ncia (baseada no desvio padr√£o normalizado)
    if len(serie_atual) > 2:
        consistencia = 1 - (serie_atual.std() / max(1e-9, serie_atual.max()))
        kpis["consistency"] = IntelligentKPI(
            "Consist√™ncia", consistencia, 0.7, lambda x: f"{x*100:.1f}%", "üéØ"
        )
    
    # Momentum (acelera√ß√£o recente)
    if len(serie_atual) >= 6:
        recent = serie_atual.tail(3).mean()
        previous = serie_atual.iloc[-6:-3].mean()
        momentum = (recent - previous) / max(1, previous)
        kpis["momentum"] = IntelligentKPI(
            "Momentum", momentum, 0.0, lambda x: f"{x*100:+.1f}%", "üöÄ"
        )
    
    # Retorna estrutura completa
    return {
        "basic_metrics": {
            "faturamento": total_faturamento,
            "pedidos": total_pedidos,
            "ticket_medio": ticket_medio,
            "periodo_anterior": periodo_anterior_valor,
        },
        "intelligent_kpis": kpis,
        "time_series": serie_atual,
        "historical_series": serie_historica,
        "outliers": detect_outliers(serie_atual) if len(serie_atual) > 5 else pd.Series(dtype=bool),
    }

# =============================================================================
# COMPONENTES VISUAIS AVAN√áADOS
# =============================================================================

def render_hero_section(periodo_ini: str, periodo_fim: str, analysis_mode: str) -> None:
    """Renderiza se√ß√£o hero com informa√ß√µes principais."""
    st.markdown(
        f"""
        <div class="hero-header">
            <h1>üìä Dashboard Inteligente v3.0</h1>
            <h3>An√°lise Avan√ßada de Performance com Machine Learning</h3>
            <p><strong>Per√≠odo:</strong> {periodo_ini} at√© {periodo_fim} | <strong>Modo:</strong> {analysis_mode}</p>
        </div>
        """,
        unsafe_allow_html=True,
    )

def render_intelligent_kpi_panel(kpis_data: Dict[str, Any]) -> None:
    """Renderiza painel de KPIs com explica√ß√µes interativas."""
    st.markdown("### üìä Indicadores Inteligentes")
    
    # KPIs b√°sicos
    basic = kpis_data["basic_metrics"]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        kpi_fat = IntelligentKPI(
            "Faturamento Total", basic["faturamento"], basic["periodo_anterior"],
            lambda x: f"R$ {x:,.2f}".replace(",", "X").replace(".", ",").replace("X", "."), "üí∞"
        )
        kpi_fat.render()
    
    with col2:
        kpi_ped = IntelligentKPI(
            "Pedidos Totais", basic["pedidos"], None,
            lambda x: f"{int(x):,}".replace(",", "."), "üõí"
        )
        kpi_ped.render()
    
    with col3:
        kpi_ticket = IntelligentKPI(
            "Ticket M√©dio", basic["ticket_medio"], None,
            lambda x: f"R$ {x:,.2f}".replace(",", "X").replace(".", ",").replace("X", "."), "üéØ"
        )
        kpi_ticket.render()
    
    with col4:
        # Percentil de performance
        serie_hist = kpis_data["historical_series"]
        if not serie_hist.empty:
            percentil = calculate_percentile_rank(basic["faturamento"], serie_hist)
            st.metric("üìà Percentil Performance", f"{percentil:.0f}%")
    
    # KPIs inteligentes avan√ßados
    if kpis_data["intelligent_kpis"]:
        st.markdown("#### KPIs Avan√ßados")
        intell_cols = st.columns(len(kpis_data["intelligent_kpis"]))
        
        for i, (key, kpi) in enumerate(kpis_data["intelligent_kpis"].items()):
            with intell_cols[i]:
                kpi.render()

def render_enhanced_top_performers(df: pd.DataFrame, periodo_ini: str, periodo_fim: str) -> None:
    """Renderiza se√ß√£o de top performers com visualiza√ß√µes aprimoradas."""
    st.markdown("### üèÜ Top Performers - An√°lise Multidimensional")
    
    # Filtrar dados do per√≠odo
    mask = (df["periodo"] >= periodo_ini) & (df["periodo"] <= periodo_fim)
    df_period = df[mask].copy()
    
    if df_period.empty:
        st.warning("N√£o h√° dados para o per√≠odo selecionado.")
        return
    
    # Agrega√ß√£o por loja com m√©tricas avan√ßadas
    agg_data = df_period.groupby("loja").agg({
        "faturamento": ["sum", "mean", "std"],
        "pedidos": ["sum", "mean"],
        "ticket": ["mean", "std"]
    }).round(2)
    
    # Flatten columns
    agg_data.columns = [f"{col[0]}_{col[1]}" for col in agg_data.columns]
    agg_data = agg_data.reset_index()
    
    # C√°lculo de scores compostos
    metrics_to_score = ["faturamento_sum", "pedidos_sum", "ticket_mean"]
    for metric in metrics_to_score:
        if metric in agg_data.columns:
            max_val = agg_data[metric].max()
            if max_val > 0:
                agg_data[f"{metric}_score"] = (agg_data[metric] / max_val) * 100
    
    # Score geral (m√©dia ponderada)
    score_cols = [col for col in agg_data.columns if col.endswith("_score")]
    if score_cols:
        weights = {"faturamento_sum_score": 0.4, "pedidos_sum_score": 0.3, "ticket_mean_score": 0.3}
        agg_data["score_geral"] = 0
        for col in score_cols:
            weight = weights.get(col, 1/len(score_cols))
            agg_data["score_geral"] += agg_data[col] * weight
    
    # Ordenar por score geral
    agg_data = agg_data.sort_values("score_geral", ascending=False)
    
    # Visualiza√ß√£o do p√≥dio aprimorado
    st.markdown("#### P√≥dio de Performance")
    
    top_3 = agg_data.head(3)
    if len(top_3) >= 3:
        podium_col1, podium_col2, podium_col3 = st.columns([1, 1.2, 1])
        
        # 2¬∫ Lugar (Prata)
        with podium_col1:
            silver = top_3.iloc[1]
            st.markdown(
                f"""
                <div class="top-performer-silver">
                    <div style="font-size: 2rem;">ü•à</div>
                    <h3>{silver['loja']}</h3>
                    <p><strong>Score: {silver['score_geral']:.1f}</strong></p>
                    <p>Faturamento: R$ {silver['faturamento_sum']:,.0f}</p>
                    <p>Pedidos: {silver['pedidos_sum']:,.0f}</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        
        # 1¬∫ Lugar (Ouro) - Maior destaque
        with podium_col2:
            gold = top_3.iloc[0]
            st.markdown(
                f"""
                <div class="top-performer-gold">
                    <div style="font-size: 3rem;">üëë</div>
                    <h2>{gold['loja']}</h2>
                    <p><strong>Score: {gold['score_geral']:.1f}</strong></p>
                    <p>Faturamento: R$ {gold['faturamento_sum']:,.0f}</p>
                    <p>Pedidos: {gold['pedidos_sum']:,.0f}</p>
                    <p>Ticket: R$ {gold['ticket_mean']:,.2f}</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        
        # 3¬∫ Lugar (Bronze)
        with podium_col3:
            bronze = top_3.iloc[2]
            st.markdown(
                f"""
                <div class="top-performer-bronze">
                    <div style="font-size: 2rem;">ü•â</div>
                    <h3>{bronze['loja']}</h3>
                    <p><strong>Score: {bronze['score_geral']:.1f}</strong></p>
                    <p>Faturamento: R$ {bronze['faturamento_sum']:,.0f}</p>
                    <p>Pedidos: {bronze['pedidos_sum']:,.0f}</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
    
    # Gr√°fico radar comparativo dos top 5
    st.markdown("#### An√°lise Radar - Top 5 Lojas")
    
    top_5 = agg_data.head(5)
    fig_radar = go.Figure()
    
    categories = ["Faturamento", "Volume Pedidos", "Ticket M√©dio", "Consist√™ncia"]
    
    for idx, (_, row) in enumerate(top_5.iterrows()):
        # Normalizar m√©tricas para 0-100
        fat_norm = (row["faturamento_sum"] / top_5["faturamento_sum"].max()) * 100
        ped_norm = (row["pedidos_sum"] / top_5["pedidos_sum"].max()) * 100  
        ticket_norm = (row["ticket_mean"] / top_5["ticket_mean"].max()) * 100
        consist_norm = 100 - ((row.get("faturamento_std", 0) / row["faturamento_mean"]) * 50) if row["faturamento_mean"] > 0 else 50
        
        fig_radar.add_trace(go.Scatterpolar(
            r=[fat_norm, ped_norm, ticket_norm, max(0, consist_norm)],
            theta=categories,
            fill='toself',
            name=row['loja'],
            line_color=COLOR_SCHEMES["primary"][idx % len(COLOR_SCHEMES["primary"])],
        ))
    
    fig_radar.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
        showlegend=True,
        title="Compara√ß√£o Multidimensional - Top 5",
        height=500
    )
    st.plotly_chart(fig_radar, use_container_width=True)
    
    # Tabela detalhada com badges de performance
    st.markdown("#### Ranking Detalhado")
    
    display_data = agg_data.copy()
    
    # Adicionar badges de performance
    def get_performance_badge(score: float) -> str:
        if score >= 80:
            return '<span class="performance-badge badge-excellent">Excelente</span>'
        elif score >= 60:
            return '<span class="performance-badge badge-good">Bom</span>'
        else:
            return '<span class="performance-badge badge-poor">Melhorar</span>'
    
    display_data["Performance"] = display_data["score_geral"].apply(get_performance_badge)
    display_data["Faturamento"] = display_data["faturamento_sum"].apply(
        lambda x: f"R$ {x:,.0f}".replace(",", "X").replace(".", ",").replace("X", ".")
    )
    display_data["Pedidos"] = display_data["pedidos_sum"].apply(lambda x: f"{x:,.0f}".replace(",", "."))
    display_data["Ticket"] = display_data["ticket_mean"].apply(
        lambda x: f"R$ {x:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")
    )
    
    # Mostrar apenas colunas relevantes
    cols_to_show = ["loja", "Performance", "Faturamento", "Pedidos", "Ticket", "score_geral"]
    final_display = display_data[cols_to_show].rename(columns={
        "loja": "Loja",
        "score_geral": "Score"
    })
    
    st.markdown(final_display.to_html(escape=False, index=False), unsafe_allow_html=True)

def render_clustering_analysis(df: pd.DataFrame) -> None:
    """An√°lise de clustering para segmenta√ß√£o autom√°tica de lojas."""
    st.markdown("### üéØ Segmenta√ß√£o Inteligente de Lojas")
    
    # Se a biblioteca scikit-learn n√£o estiver instalada, informamos o usu√°rio e encerramos a fun√ß√£o.
    if not HAS_SKLEARN:
        st.info("Clustering requer a biblioteca scikit-learn. Instale-a para habilitar este m√≥dulo.")
        return
    
    # Preparar dados para clustering
    features_data = df.groupby("loja").agg({
        "faturamento": ["mean", "std"],
        "pedidos": ["mean", "std"], 
        "ticket": ["mean", "std"]
    })
    
    features_data.columns = [f"{col[0]}_{col[1]}" for col in features_data.columns]
    features_data = features_data.fillna(0)
    
    if len(features_data) < 3:
        st.info("Clustering requer pelo menos 3 lojas para an√°lise.")
        return
    
    # Normalizar features
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features_data)
    
    # Determinar n√∫mero √≥timo de clusters
    n_clusters = min(4, len(features_data) // 2 + 1)
    
    # K-means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(features_scaled)
    
    features_data["cluster"] = clusters
    features_data["loja"] = features_data.index
    
    # Visualiza√ß√£o 3D dos clusters
    fig_cluster = px.scatter_3d(
        features_data,
        x="faturamento_mean",
        y="pedidos_mean", 
        z="ticket_mean",
        color="cluster",
        hover_name="loja",
        title="Segmenta√ß√£o Autom√°tica de Lojas",
        labels={
            "faturamento_mean": "Faturamento M√©dio",
            "pedidos_mean": "Pedidos M√©dios",
            "ticket_mean": "Ticket M√©dio"
        },
        color_continuous_scale="Viridis"
    )
    fig_cluster.update_layout(height=600)
    st.plotly_chart(fig_cluster, use_container_width=True)
    
    # An√°lise dos clusters
    st.markdown("#### Caracter√≠sticas dos Segmentos")
    
    cluster_analysis = features_data.groupby("cluster").agg({
        "faturamento_mean": "mean",
        "pedidos_mean": "mean",
        "ticket_mean": "mean"
    }).round(0)
    
    cluster_names = {
        0: "High Volume",
        1: "Premium",
        2: "Balanced",
        3: "Growing"
    }
    
    for cluster_id, row in cluster_analysis.iterrows():
        cluster_name = cluster_names.get(cluster_id, f"Segmento {cluster_id}")
        lojas_no_cluster = features_data[features_data["cluster"] == cluster_id]["loja"].tolist()
        
        st.markdown(f"**{cluster_name}** ({len(lojas_no_cluster)} lojas)")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Fat. M√©dio", f"R$ {row['faturamento_mean']:,.0f}".replace(",", "."))
        with col2:
            st.metric("Ped. M√©dios", f"{row['pedidos_mean']:,.0f}".replace(",", "."))
        with col3:
            st.metric("Ticket M√©dio", f"R$ {row['ticket_mean']:,.2f}".replace(",", "X").replace(".", ",").replace("X", "."))
        
        st.caption(f"Lojas: {', '.join(lojas_no_cluster)}")
        st.markdown("---")

def render_forecasting_module(kpis_data: Dict[str, Any], periods: int = 6) -> None:
    """M√≥dulo avan√ßado de previs√£o com m√∫ltiplos modelos."""
    st.markdown("### üîÆ Previs√µes Inteligentes")
    
    serie = kpis_data["time_series"]
    
    if len(serie) < 12:
        st.warning("Previs√µes requerem pelo menos 12 meses de dados hist√≥ricos.")
        return
    
    # Controles de previs√£o
    forecast_col1, forecast_col2 = st.columns(2)
    with forecast_col1:
        forecast_periods = st.slider("Per√≠odos para Prever", 3, 12, periods)
    with forecast_col2:
        confidence_level = st.selectbox("N√≠vel de Confian√ßa", [80, 90, 95], index=1)
    
    if not HAS_STATSMODELS:
        st.error("M√≥dulo de previs√£o requer statsmodels. Instale com: pip install statsmodels")
        return
    
    try:
        # Preparar s√©rie temporal
        ts_data = serie.copy()
        ts_data.index = pd.to_datetime(ts_data.index)
        ts_data = ts_data.asfreq("MS").fillna(method="ffill")
        
        # Modelo Holt-Winters
        model = ExponentialSmoothing(
            ts_data,
            trend="add",
            seasonal="add",
            seasonal_periods=12
        ).fit()
        
        forecast = model.forecast(forecast_periods)
        forecast_dates = pd.date_range(
            start=ts_data.index[-1] + pd.DateOffset(months=1),
            periods=forecast_periods,
            freq="MS"
        )
        
        # Intervalo de confian√ßa (aproximado)
        forecast_std = ts_data.std()
        z_score = {80: 1.28, 90: 1.64, 95: 1.96}[confidence_level]
        confidence_interval = z_score * forecast_std
        
        # Visualiza√ß√£o
        fig_forecast = go.Figure()
        
        # Dados hist√≥ricos
        fig_forecast.add_trace(go.Scatter(
            x=ts_data.index,
            y=ts_data.values,
            mode="lines+markers",
            name="Hist√≥rico",
            line=dict(color="#667eea", width=3),
        ))
        
        # Previs√£o
        fig_forecast.add_trace(go.Scatter(
            x=forecast_dates,
            y=forecast.values,
            mode="lines+markers", 
            name="Previs√£o",
            line=dict(color="#f5576c", width=3, dash="dash"),
        ))
        
        # Intervalo de confian√ßa
        fig_forecast.add_trace(go.Scatter(
            x=list(forecast_dates) + list(forecast_dates[::-1]),
            y=list(forecast + confidence_interval) + list((forecast - confidence_interval)[::-1]),
            fill="toself",
            fillcolor="rgba(245,87,108,0.2)",
            line=dict(color="rgba(255,255,255,0)"),
            name=f"IC {confidence_level}%",
            showlegend=True,
        ))
        
        fig_forecast.update_layout(
            title=f"Previs√£o de Faturamento - Pr√≥ximos {forecast_periods} Meses",
            xaxis_title="Per√≠odo",
            yaxis_title="Faturamento (R$)",
            height=500,
            hovermode="x unified"
        )
        
        st.plotly_chart(fig_forecast, use_container_width=True)
        
        # M√©tricas de previs√£o
        forecast_col1, forecast_col2, forecast_col3, forecast_col4 = st.columns(4)
        
        with forecast_col1:
            st.metric(
                "Pr√≥ximo M√™s",
                f"R$ {forecast.iloc[0]:,.0f}".replace(",", "."),
                help="Previs√£o para o pr√≥ximo per√≠odo"
            )
        with forecast_col2:
            st.metric(
                "M√©dia Prevista", 
                f"R$ {forecast.mean():,.0f}".replace(",", "."),
                help="M√©dia dos pr√≥ximos per√≠odos"
            )
        with forecast_col3:
            total_previsto = forecast.sum()
            total_atual = ts_data.tail(forecast_periods).sum()
            variacao = ((total_previsto - total_atual) / total_atual) * 100 if total_atual > 0 else 0
            st.metric(
                "Total Previsto",
                f"R$ {total_previsto:,.0f}".replace(",", "."),
                f"{variacao:+.1f}%",
                help="Soma dos pr√≥ximos per√≠odos vs. √∫ltimos per√≠odos"
            )
        with forecast_col4:
            acuracia = 100 - abs(forecast_std / ts_data.mean()) * 100 if ts_data.mean() > 0 else 0
            st.metric(
                "Confiabilidade",
                f"{max(0, acuracia):.0f}%",
                help="Estimativa de confiabilidade do modelo"
            )
        
        # Explica√ß√£o do modelo
        with st.expander("üî¨ Como funciona a previs√£o?"):
            st.markdown("""
            **Modelo Holt-Winters (Suaviza√ß√£o Exponencial):**
            
            - **Tend√™ncia**: Captura a dire√ß√£o geral de crescimento/decl√≠nio
            - **Sazonalidade**: Identifica padr√µes recorrentes (ex: meses mais fortes)
            - **Suaviza√ß√£o**: Reduz ru√≠do mantendo padr√µes importantes
            
            **Intervalo de Confian√ßa**: Indica a faixa prov√°vel onde o valor real pode estar.
            Maior intervalo = maior incerteza na previs√£o.
            
            **Limita√ß√µes**: Assume que padr√µes passados se repetir√£o. Eventos externos 
            (crises, promo√ß√µes, mudan√ßas sazonais) podem afetar a precis√£o.
            """)
    except Exception as e:
        st.error(f"Erro na gera√ß√£o de previs√µes: {str(e)}")

def render_anomaly_detection(kpis_data: Dict[str, Any]) -> None:
    """Detecta e visualiza anomalias na s√©rie temporal."""
    st.markdown("### üîç Detec√ß√£o de Anomalias")
    
    serie = kpis_data["time_series"]
    outliers = kpis_data["outliers"]
    
    if serie.empty or len(serie) < 6:
        st.info("Detec√ß√£o de anomalias requer pelo menos 6 pontos de dados.")
        return
    
    # Calcular limites de controle estat√≠stico
    mean_value = serie.mean()
    std_value = serie.std()
    upper_limit = mean_value + 2 * std_value
    lower_limit = mean_value - 2 * std_value
    
    # Detectar anomalias por diferentes m√©todos
    z_scores = np.abs(zscore(serie))
    anomalias_zscore = z_scores > 2.0
    
    # Visualiza√ß√£o
    fig_anomaly = go.Figure()
    
    # S√©rie normal
    normal_mask = ~anomalias_zscore
    fig_anomaly.add_trace(go.Scatter(
        x=serie.index[normal_mask],
        y=serie.values[normal_mask],
        mode="lines+markers",
        name="Normal",
        line=dict(color="#28a745", width=2),
        marker=dict(size=6)
    ))
    
    # Anomalias
    if anomalias_zscore.any():
        fig_anomaly.add_trace(go.Scatter(
            x=serie.index[anomalias_zscore],
            y=serie.values[anomalias_zscore],
            mode="markers",
            name="Anomalias",
            marker=dict(color="#dc3545", size=12, symbol="x")
        ))
    
    # Limites de controle
    fig_anomaly.add_hline(y=upper_limit, line_dash="dash", line_color="#ffc107", 
                          annotation_text="Limite Superior")
    fig_anomaly.add_hline(y=lower_limit, line_dash="dash", line_color="#ffc107",
                          annotation_text="Limite Inferior")
    fig_anomaly.add_hline(y=mean_value, line_dash="dot", line_color="#6c757d",
                          annotation_text="M√©dia")
    
    fig_anomaly.update_layout(
        title="Detec√ß√£o de Anomalias - Controle Estat√≠stico",
        xaxis_title="Per√≠odo",
        yaxis_title="Faturamento (R$)",
        height=400
    )
    
    st.plotly_chart(fig_anomaly, use_container_width=True)
    
    # Resumo das anomalias
    if anomalias_zscore.any():
        anomaly_dates = serie.index[anomalias_zscore]
        anomaly_values = serie.values[anomalias_zscore]
        
        st.markdown("#### Per√≠odos An√¥malos Detectados")
        for date, value in zip(anomaly_dates, anomaly_values):
            deviation = ((value - mean_value) / mean_value) * 100
            alert_type = "success" if deviation > 0 else "warning"
            direction = "acima" if deviation > 0 else "abaixo"
            
            st.markdown(
                f"""
                <div class="alert-{alert_type}">
                    <strong>{date.strftime('%m/%Y')}</strong>: 
                    R$ {value:,.0f} ({deviation:+.1f}% {direction} da m√©dia)
                </div>
                """.replace(",", "."),
                unsafe_allow_html=True
            )
    else:
        st.success("‚úÖ Nenhuma anomalia significativa detectada no per√≠odo.")

def render_business_insights_engine(kpis_data: Dict[str, Any], df: pd.DataFrame) -> None:
    """Motor de insights de neg√≥cio baseado em regras e padr√µes."""
    st.markdown("### üí° Engine de Insights de Neg√≥cio")
    
    insights = []
    
    # An√°lise dos KPIs inteligentes
    intelligent_kpis = kpis_data.get("intelligent_kpis", {})
    
    # Growth insights
    if "growth_rate" in intelligent_kpis:
        growth_kpi = intelligent_kpis["growth_rate"]
        growth_class, _ = growth_kpi.performance_class
        
        if growth_class == "excelente":
            insights.append({
                "type": "success",
                "title": "Crescimento Acelerado",
                "description": f"Taxa de crescimento de {growth_kpi.value*100:.1f}% indica momentum forte. Considere expandir capacidade.",
                "action": "Avaliar abertura de novas unidades ou amplia√ß√£o do mix de produtos.",
                "priority": "alta"
            })
        elif growth_class == "atencao":
            insights.append({
                "type": "warning", 
                "title": "Crescimento Desacelerado",
                "description": f"Taxa de {growth_kpi.value*100:.1f}% sugere necessidade de revis√£o estrat√©gica.",
                "action": "Implementar campanhas de reten√ß√£o e an√°lise de concorr√™ncia.",
                "priority": "alta"
            })
    
    # Volatility insights
    if "volatility" in intelligent_kpis:
        vol_kpi = intelligent_kpis["volatility"]
        vol_class, _ = vol_kpi.performance_class
        
        if vol_class == "atencao":
            insights.append({
                "type": "warning",
                "title": "Alta Variabilidade",
                "description": f"Volatilidade de {vol_kpi.value*100:.1f}% indica vendas inst√°veis.",
                "action": "Implementar estrat√©gias de estabiliza√ß√£o da demanda.",
                "priority": "media"
            })
    
    # Efficiency insights
    if "efficiency" in intelligent_kpis:
        eff_kpi = intelligent_kpis["efficiency"]
        eff_class, _ = eff_kpi.performance_class
        
        if eff_class == "excelente":
            insights.append({
                "type": "success",
                "title": "Efici√™ncia Operacional Superior", 
                "description": f"Performance {eff_kpi.value*100:+.1f}% acima do hist√≥rico.",
                "action": "Documentar melhores pr√°ticas para replicar em outras lojas.",
                "priority": "media"
            })
    
    # An√°lise sazonal
    serie = kpis_data["time_series"]
    if len(serie) >= 12:
        monthly_avg = serie.groupby(serie.index.month).mean()
        best_month = monthly_avg.idxmax()
        worst_month = monthly_avg.idxmin()
        
        month_names = {1: "Jan", 2: "Fev", 3: "Mar", 4: "Abr", 5: "Mai", 6: "Jun",
                      7: "Jul", 8: "Ago", 9: "Set", 10: "Out", 11: "Nov", 12: "Dez"}
        
        insights.append({
            "type": "info",
            "title": "Padr√£o Sazonal Identificado",
            "description": f"Melhor m√™s: {month_names[best_month]} | Pior m√™s: {month_names[worst_month]}",
            "action": "Planejar campanhas e estoques baseados no ciclo sazonal.",
            "priority": "baixa"
        })
    
    # Renderizar insights
    if insights:
        # Separar por prioridade
        high_priority = [i for i in insights if i["priority"] == "alta"]
        medium_priority = [i for i in insights if i["priority"] == "media"]
        low_priority = [i for i in insights if i["priority"] == "baixa"]
        
        for priority_group, title in [(high_priority, "üö® Alta Prioridade"), 
                                      (medium_priority, "‚ö†Ô∏è M√©dia Prioridade"),
                                      (low_priority, "üí° Informativo")]:
            if priority_group:
                st.markdown(f"#### {title}")
                for insight in priority_group:
                    st.markdown(
                        f"""
                        <div class="alert-{insight['type']}">
                            <h5>{insight['title']}</h5>
                            <p>{insight['description']}</p>
                            <small><strong>A√ß√£o sugerida:</strong> {insight['action']}</small>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
    else:
        st.info("Nenhum insight cr√≠tico identificado no momento.")

def render_interactive_explanations() -> None:
    """Se√ß√£o de explica√ß√µes interativas sobre KPIs e m√©tricas."""
    st.markdown("### üìö Central de Conhecimento")
    
    with st.expander("üìä Explica√ß√£o dos KPIs Principais"):
        tab1, tab2, tab3 = st.tabs(["M√©tricas B√°sicas", "KPIs Avan√ßados", "Algoritmos ML"])
        
        with tab1:
            st.markdown("""
            **Faturamento Total**: Soma de todas as receitas no per√≠odo
            - **C√°lculo**: Œ£(vendas_per√≠odo)
            - **Uso**: Medir volume de neg√≥cio e comparar per√≠odos
            
            **Ticket M√©dio**: Valor m√©dio por transa√ß√£o
            - **C√°lculo**: Faturamento Total √∑ N√∫mero de Pedidos  
            - **Uso**: Entender valor por cliente e identificar oportunidades de upsell
            
            **Taxa de Convers√£o**: Efici√™ncia em converter visitantes em vendas
            - **C√°lculo**: (Pedidos √∑ Visitantes) √ó 100
            - **Uso**: Otimizar processos de venda
            """)
        
        with tab2:
            st.markdown("""
            **Taxa de Crescimento Composto**: Crescimento m√©dio por per√≠odo
            - **C√°lculo**: ((Valor_Final √∑ Valor_Inicial)^(1/per√≠odos)) - 1
            - **Uso**: Projetar crescimento sustent√°vel
            
            **Volatilidade (Coeficiente de Varia√ß√£o)**: Estabilidade das vendas
            - **C√°lculo**: Desvio_Padr√£o √∑ M√©dia
            - **Uso**: Avaliar previsibilidade e risco operacional
            
            **Efici√™ncia Operacional**: Performance vs. benchmark hist√≥rico
            - **C√°lculo**: (Ticket_Atual √∑ Ticket_Hist√≥rico) - 1
            - **Uso**: Identificar melhorias operacionais
            """)
        
        with tab3:
            st.markdown("""
            **K-Means Clustering**: Segmenta√ß√£o autom√°tica de lojas
            - **Algoritmo**: Agrupa lojas por similaridade de performance
            - **Uso**: Estrat√©gias diferenciadas por segmento
            
            **Z-Score (Detec√ß√£o de Anomalias)**: Identifica per√≠odos at√≠picos
            - **C√°lculo**: (Valor - M√©dia) √∑ Desvio_Padr√£o
            - **Uso**: Investigar causas de varia√ß√µes extremas
            
            **Holt-Winters**: Previs√£o com tend√™ncia e sazonalidade
            - **Algoritmo**: Suaviza√ß√£o exponencial tripla
            - **Uso**: Planejamento de demanda e estoques
            """)

# =============================================================================
# FUN√á√ÉO PRINCIPAL OTIMIZADA
# =============================================================================

def main() -> None:
    """Fun√ß√£o principal com fluxo otimizado e componentes modulares."""
    
    # Configura√ß√£o inicial
    configure_advanced_page()
    
    # Carregamento de dados com cache inteligente
    df = load_enhanced_data()
    
    if df.empty:
        st.error("N√£o foi poss√≠vel carregar dados. Verifique os arquivos CSV.")
        st.stop()
    
    # Sidebar com filtros avan√ßados
    with st.sidebar:
        st.markdown("### üéõÔ∏è Controles Avan√ßados")
        
        # Sele√ß√£o de modo
        analysis_modes = {
            "Dashboard Geral": "Vis√£o completa com todos os m√≥dulos",
            "Top Performers": "Foco em ranking e segmenta√ß√£o", 
            "Previs√µes": "An√°lise preditiva e tend√™ncias",
            "Anomalias": "Detec√ß√£o de padr√µes at√≠picos"
        }
        
        selected_mode = st.selectbox(
            "Modo de An√°lise",
            list(analysis_modes.keys()),
            help="Escolha o foco da an√°lise"
        )
        
        st.caption(analysis_modes[selected_mode])
        
        # Filtros de per√≠odo
        periodos = sorted(df["periodo"].unique())
        if len(periodos) < 2:
            st.error("Dados insuficientes para an√°lise.")
            st.stop()
        
        periodo_range = st.select_slider(
            "Per√≠odo de An√°lise",
            options=periodos,
            value=(periodos[max(0, len(periodos)-12)], periodos[-1]),
            help="Selecione o intervalo de meses para an√°lise"
        )
        
        periodo_ini, periodo_fim = periodo_range
        
        # Sele√ß√£o de lojas
        st.markdown("#### Filtro de Lojas")
        lojas_disponiveis = sorted(df["loja"].unique())
        
        selection_mode = st.radio(
            "Modo de Sele√ß√£o",
            ["Todas", "Top Performers", "Manual", "Por Score"],
            help="Como selecionar as lojas para an√°lise"
        )
        
        if selection_mode == "Todas":
            selected_lojas = lojas_disponiveis
        elif selection_mode == "Top Performers":
            n_top = st.slider("Quantas lojas?", 3, len(lojas_disponiveis), 5)
            # Calcular top por faturamento no per√≠odo
            period_mask = (df["periodo"] >= periodo_ini) & (df["periodo"] <= periodo_fim)
            top_lojas_fat = (df[period_mask].groupby("loja")["faturamento"]
                           .sum().nlargest(n_top).index.tolist())
            selected_lojas = top_lojas_fat
        elif selection_mode == "Manual":
            selected_lojas = st.multiselect(
                "Escolha as lojas:",
                lojas_disponiveis,
                default=lojas_disponiveis[:3]
            )
        else:  # Por Score
            min_score = st.slider("Score m√≠nimo", 0, 100, 70)
            # Calcular scores rapidamente
            period_mask = (df["periodo"] >= periodo_ini) & (df["periodo"] <= periodo_fim)
            scores = df[period_mask].groupby("loja").agg({
                "faturamento": "sum",
                "pedidos": "sum"
            })
            scores["score"] = (scores["faturamento"] / scores["faturamento"].max() * 50 + 
                             scores["pedidos"] / scores["pedidos"].max() * 50)
            qualified_lojas = scores[scores["score"] >= min_score].index.tolist()
            selected_lojas = st.multiselect(
                "Lojas qualificadas:",
                qualified_lojas,
                default=qualified_lojas
            )
        
        if not selected_lojas:
            selected_lojas = lojas_disponiveis[:3]
            st.warning("Nenhuma loja selecionada. Usando padr√£o.")
        
        # Op√ß√µes avan√ßadas
        st.markdown("#### Op√ß√µes Avan√ßadas")
        show_forecasts = st.checkbox("Habilitar Previs√µes", value=True)
        show_clustering = st.checkbox("An√°lise de Segmenta√ß√£o", value=True)
        show_anomalies = st.checkbox("Detec√ß√£o de Anomalias", value=True)
        
        # Informa√ß√µes do dataset
        st.markdown("---")
        st.markdown("### Informa√ß√µes do Dataset")
        st.metric("Total de Registros", len(df))
        st.metric("Lojas Dispon√≠veis", len(lojas_disponiveis))
        st.metric("Per√≠odo dos Dados", f"{periodos[0]} a {periodos[-1]}")
        
        if st.button("Limpar Cache"):
            st.cache_data.clear()
            st.success("Cache limpo!")
            st.rerun()
    
    # Filtrar dados
    period_mask = ((df["periodo"] >= periodo_ini) & 
                   (df["periodo"] <= periodo_fim) & 
                   df["loja"].isin(selected_lojas))
    df_filtered = df[period_mask].copy()
    df_historical = df[df["loja"].isin(selected_lojas)].copy()
    
    if df_filtered.empty:
        st.error("Nenhum dado encontrado para os filtros selecionados.")
        st.stop()
    
    # Header principal
    render_hero_section(periodo_ini, periodo_fim, selected_mode)
    
    # Computar KPIs
    kpis_data = compute_advanced_kpis(df_filtered, df_historical)
    
    # Renderiza√ß√£o baseada no modo selecionado
    if selected_mode == "Dashboard Geral":
        render_intelligent_kpi_panel(kpis_data)
        render_enhanced_top_performers(df, periodo_ini, periodo_fim)
        
        if show_clustering:
            render_clustering_analysis(df_filtered)
        
        if show_anomalies:
            render_anomaly_detection(kpis_data)
        
        if show_forecasts:
            render_forecasting_module(kpis_data)
        
        render_business_insights_engine(kpis_data, df_filtered)
        render_interactive_explanations()
        
    elif selected_mode == "Top Performers":
        render_intelligent_kpi_panel(kpis_data)
        render_enhanced_top_performers(df, periodo_ini, periodo_fim)
        
        if show_clustering:
            render_clustering_analysis(df_filtered)
        
    elif selected_mode == "Previs√µes":
        render_intelligent_kpi_panel(kpis_data)
        render_forecasting_module(kpis_data)
        render_business_insights_engine(kpis_data, df_filtered)
        
    elif selected_mode == "Anomalias":
        render_intelligent_kpi_panel(kpis_data)
        render_anomaly_detection(kpis_data)
        render_business_insights_engine(kpis_data, df_filtered)
    
    # Se√ß√£o de performance da aplica√ß√£o
    with st.expander("‚ö° Performance da Aplica√ß√£o"):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Registros Processados", len(df_filtered))
        with col2:
            st.metric("Lojas Analisadas", len(selected_lojas))
        with col3:
            cache_info = st.cache_data.get_stats()
            st.metric("Cache Hits", len(cache_info))

def render_advanced_evolution_charts(kpis_data: Dict[str, Any]) -> None:
    """Gr√°ficos avan√ßados de evolu√ß√£o temporal com an√°lises estat√≠sticas."""
    st.markdown("### üìà Evolu√ß√£o Temporal Avan√ßada")
    
    serie = kpis_data["time_series"]
    if serie.empty:
        st.info("N√£o h√° dados suficientes para an√°lise temporal.")
        return
    
    # Preparar dados para visualiza√ß√µes
    df_evolution = pd.DataFrame({
        "data": serie.index,
        "faturamento": serie.values
    })
    
    # Adicionar m√©dias m√≥veis e tend√™ncias
    df_evolution["mm_3"] = df_evolution["faturamento"].rolling(3).mean()
    df_evolution["mm_6"] = df_evolution["faturamento"].rolling(6).mean()
    
    # Regress√£o linear para tend√™ncia
    if len(df_evolution) > 3:
        x = np.arange(len(df_evolution))
        coeffs = np.polyfit(x, df_evolution["faturamento"], 1)
        df_evolution["tendencia"] = np.poly1d(coeffs)(x)
    
    # Gr√°fico principal de evolu√ß√£o
    fig_evolution = make_subplots(
        rows=2, cols=2,
        subplot_titles=("Faturamento e Tend√™ncias", "Velocidade de Mudan√ßa", 
                       "An√°lise de Distribui√ß√£o", "Autocorrela√ß√£o"),
        specs=[[{"secondary_y": True}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # Gr√°fico 1: Faturamento principal
    fig_evolution.add_trace(
        go.Scatter(x=df_evolution["data"], y=df_evolution["faturamento"],
                  mode="lines+markers", name="Faturamento",
                  line=dict(color="#667eea", width=3)), row=1, col=1
    )
    
    if "mm_3" in df_evolution.columns:
        fig_evolution.add_trace(
            go.Scatter(x=df_evolution["data"], y=df_evolution["mm_3"],
                      mode="lines", name="MM 3M", 
                      line=dict(color="#f093fb", dash="dot")), row=1, col=1
        )
    
    if "tendencia" in df_evolution.columns:
        fig_evolution.add_trace(
            go.Scatter(x=df_evolution["data"], y=df_evolution["tendencia"],
                      mode="lines", name="Tend√™ncia Linear",
                      line=dict(color="#f5576c", dash="dash")), row=1, col=1
        )
    
    # Gr√°fico 2: Velocidade de mudan√ßa (derivada)
    if len(df_evolution) > 1:
        mudanca = df_evolution["faturamento"].pct_change() * 100
        fig_evolution.add_trace(
            go.Bar(x=df_evolution["data"], y=mudanca,
                  name="Varia√ß√£o %", marker_color="#28a745"), row=1, col=2
        )
    
    # Gr√°fico 3: Distribui√ß√£o
    fig_evolution.add_trace(
        go.Histogram(x=df_evolution["faturamento"], nbinsx=20,
                    name="Distribui√ß√£o", marker_color="#17a2b8"), row=2, col=1
    )
    
    # Gr√°fico 4: Autocorrela√ß√£o (se statsmodels dispon√≠vel)
    if HAS_STATSMODELS and len(serie) > 10:
        try:
            lags = min(10, len(serie) // 3)
            autocorr = [serie.autocorr(lag=i) for i in range(1, lags + 1)]
            fig_evolution.add_trace(
                go.Bar(x=list(range(1, lags + 1)), y=autocorr,
                      name="Autocorrela√ß√£o", marker_color="#fd7e14"), row=2, col=2
            )
        except:
            pass
    
    fig_evolution.update_layout(height=700, showlegend=True)
    st.plotly_chart(fig_evolution, use_container_width=True)

# =============================================================================
# EXECU√á√ÉO PRINCIPAL
# =============================================================================

if __name__ == "__main__":
    main()
